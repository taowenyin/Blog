<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/atom.xml" title="BearCoding" type="application/atom+xml"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><meta name="description" content="介绍优化问题\[\begin{matrix}     minimize &amp;amp; f_{0}\left ( \mathbf{x} \right ) &amp;amp; \\      st. &amp;amp; f_{i}\left ( \mathbf{x} \right ) \leq b_{i} &amp;amp; i=1,\cdots ,M\\      variables &amp;amp; \mathbf{x} &amp;am"><meta property="og:type" content="article"><meta property="og:title" content="优化理论和应用"><meta property="og:url" content="bearcoding.cn&#x2F;optimization-theory-applications&#x2F;index.html"><meta property="og:site_name" content="BearCoding"><meta property="og:description" content="介绍优化问题\[\begin{matrix}     minimize &amp;amp; f_{0}\left ( \mathbf{x} \right ) &amp;amp; \\      st. &amp;amp; f_{i}\left ( \mathbf{x} \right ) \leq b_{i} &amp;amp; i=1,\cdots ,M\\      variables &amp;amp; \mathbf{x} &amp;am"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2020-06-28T09:20:19.948Z"><meta name="twitter:card" content="summary"><link rel="canonical" href="bearcoding.cn/optimization-theory-applications/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>优化理论和应用 | BearCoding</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">BearCoding</span><span class="logo-line-after"><i></i></span></a></div></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li class="menu-item menu-item-publication"><a href="/categories/%E5%8F%91%E8%A1%A8" rel="section"><i class="fa fa-fw fa-leanpub"></i> 发表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="bearcoding.cn/optimization-theory-applications/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="陶文寅"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="BearCoding"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 优化理论和应用</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-01 19:25:21" itemprop="dateCreated datePublished" datetime="2020-01-01T19:25:21+08:00">2020-01-01</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-06-28 17:20:19" itemprop="dateModified" datetime="2020-06-28T17:20:19+08:00">2020-06-28</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E8%AF%BE%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">课程</span></a></span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="介绍">介绍</h1><h2 id="优化问题">优化问题</h2><p><span class="math display">\[\begin{matrix} minimize &amp; f_{0}\left ( \mathbf{x} \right ) &amp; \\ st. &amp; f_{i}\left ( \mathbf{x} \right ) \leq b_{i} &amp; i=1,\cdots ,M\\ variables &amp; \mathbf{x} &amp; \end{matrix}\]</span></p><a id="more"></a><p><span class="math inline">\(\mathbf{x}=\left(x_{1}, \dots, x_{n}\right)^{\top}\)</span>：优化变量</p><p><span class="math inline">\(f_{0}: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>：目标函数</p><p><span class="math inline">\(f_{i}: \mathbb{R}^{n} \rightarrow \mathbb{R}, i=1, \ldots, M\)</span>：约束函数</p><p>最优解：在满足约束的情况下，<span class="math inline">\(\mathbf{X}^{\star}\)</span>是<span class="math inline">\(f_{0}\)</span>中所有向量的最小值。</p><p>可以高效可靠解决的问题：</p><blockquote><ul><li>1、线性规划问题</li><li>2、最小二乘问题</li><li>3、凸优化问题</li></ul></blockquote><h2 id="线性规划问题">线性规划问题</h2><p><span class="math display">\[\begin{matrix} minimize &amp; \mathbf{c}^{\top} \mathbf{x} &amp; \\ st. &amp; \mathbf{a}_{i}^{\top} \mathbf{x} \leq b_{i} &amp; i=1,\cdots ,M\\ variables &amp; \mathbf{x} &amp; \end{matrix}\]</span></p><h3 id="整数线性规划问题">整数线性规划问题</h3><p><span class="math display">\[\begin{matrix} minimize &amp; \mathbf{c}^{\top} \mathbf{x} &amp; \\ st. &amp; \mathbf{a}_{i}^{\top} \mathbf{x} \leq b_{i} &amp; i=1,\cdots ,M\\ &amp; \mathbf{x} \in \mathbb{Z}^{n} &amp; \\ variables &amp; \mathbf{x} &amp; \end{matrix}\]</span></p><h2 id="最小二乘问题">最小二乘问题</h2><p><span class="math display">\[\begin{matrix} minimize &amp; \left \| \mathbf{A}\mathbf{x}-\mathbf{b} \right \|_{2}^{2} &amp; \\ variables &amp; \mathbf{x} &amp; \end{matrix}\]</span></p><h2 id="凸优化问题">凸优化问题</h2><p><span class="math display">\[\begin{matrix} minimize &amp; f_{0}(\mathbf{x}) &amp; \\ st. &amp; f_{i}(\mathbf{x}) \leq b_{i} &amp; i=1,\cdots ,M\\ variables &amp; \mathbf{x} &amp; \end{matrix}\]</span></p><blockquote><ul><li>目标函数和约束函数都是凸函数。</li></ul></blockquote><p><span class="math inline">\(f_{i}(\alpha \mathbf{x}+\beta \mathbf{y}) \leq \alpha f_{i}(\mathbf{x})+\beta f_{i}(\mathbf{y})\)</span>， 假如<span class="math inline">\(\alpha+\beta=1, \alpha \geq 0, \beta \geq 0\)</span></p><blockquote><ul><li>最小二乘和特殊情况下的线性规划是凸优化问题。</li></ul></blockquote><h2 id="优化模型分类">优化模型分类</h2><blockquote><ul><li>1、按照解决方法：数值优化和分析优化。</li><li>2、按照约束条件：无约束优化和有约束优化，其中有约束优化分为集约束优化、等式约束优化、不等式约束优化。</li><li>3、按照信息完整性：正态优化和信息不确定性的优化，其中信息不确定性的优化分为随机优化和鲁棒优化。</li><li>4、按照问题属性：线性规划和非线性规划，其中非线性规划分为凸优化、二次规划、一般非线性规划。</li><li>5、按照目标：单目标优化和多目标优化。</li></ul></blockquote><h1 id="基础知识">基础知识</h1><h2 id="符号说明">符号说明</h2><p>1、<span class="math inline">\(\mathbb{X}\)</span>是一个集合，<span class="math inline">\(x \in \mathbb{X}\)</span>表示<span class="math inline">\(x\)</span>是<span class="math inline">\(\mathbb{X}\)</span>中的元素。</p><p>2、<span class="math inline">\(\{x 1, x 2, x 3, \ldots\}\)</span>和<span class="math inline">\(\{x: x \in \mathbb{R}, x&gt;5\}\)</span>都可以表示一个集合。</p><p>3、<span class="math inline">\(\mathbb{X}\)</span>和<span class="math inline">\(\mathbb{Y}\)</span>都是集合，如果<span class="math inline">\(\mathbb{X} \subset \mathbb{Y}\)</span>，那么表示<span class="math inline">\(\mathbb{X}\)</span>是<span class="math inline">\(\mathbb{Y}\)</span>的子集。</p><p>4、<span class="math inline">\(f: \mathbb{X} \rightarrow \mathbb{Y}\)</span>表示<span class="math inline">\(f\)</span>是从集合<span class="math inline">\(\mathbb{X}\)</span>到<span class="math inline">\(\mathbb{Y}\)</span>的函数。</p><p>5、<span class="math inline">\(\overset{\triangle}{=}\)</span>表示“定义为”。</p><p>6、假设定义n阶向量<span class="math inline">\(\mathbf{a}=\left[\begin{array}{c}{a_{1}} \\ {a_{2}} \\ {\vdots} \\ {a_{n}}\end{array}\right]\)</span>，那么<span class="math inline">\(\mathbf{a}^{\top}=\left[a_{1}, a_{2}, \ldots, a_{n}\right]\)</span>。</p><h2 id="线性相关">线性相关</h2><p>向量集<span class="math inline">\(\left \{ \mathbf{a_{1}},\mathbf{a_{2}},\cdots ,\mathbf{a_{k}} \right \}\)</span>是线性相关，当且仅当集合中的一个向量可以表示为其他向量的线性组合。</p><p>必要条件：<span class="math inline">\(\alpha_{1}\mathbf{a_{1}}+\alpha_{2}\mathbf{a_{2}}+\cdots +\alpha_{k}\mathbf{a_{k}}=\mathbf{0}\)</span>，并且其中至少有一个<span class="math inline">\(\alpha_{i} \neq 0\)</span>，否则就是不相关。</p><p>充分条件：<span class="math inline">\(\left ( -1 \right )\mathbf{a_{1}}+\alpha_{2}\mathbf{a_{2}}+\cdots +\alpha_{k}\mathbf{a_{k}}=\mathbf{0}\)</span></p><h2 id="二次型函数">二次型函数</h2><p><span class="math display">\[f\left ( \mathbf{x} \right )=\mathbf{x}^{\top}\mathbf{Q}\mathbf{x}\]</span></p><p>对于任意非零向量<span class="math inline">\(\mathbf{x}\)</span>，都有<span class="math inline">\(\mathbf{x}^{\top}\mathbf{Q}\mathbf{x} &gt; 0\)</span>，并且如果<span class="math inline">\(\mathbf{Q}=\mathbf{Q}^{T}\)</span>，那么<span class="math inline">\(\mathbf{Q}\)</span>是正定的。如果<span class="math inline">\(\mathbf{x}^{\top}\mathbf{Q}\mathbf{x} \geq 0\)</span>，那么<span class="math inline">\(\mathbf{Q}\)</span>是半正定的。相反，还是负定和半负定。</p><h3 id="二次规划">二次规划</h3><p><span class="math display">\[\begin{matrix} minimize &amp; \mathbf{x}^{\top}\mathbf{Q}\mathbf{x} + \mathbf{c}^{\top}\mathbf{x} \\ st. &amp; \mathbf{Ax}\leq \mathbf{b}\\ \end{matrix}\]</span></p><h3 id="线性规划最优控制">线性规划最优控制</h3><p><span class="math display">\[\begin{matrix} minimize &amp; J\left(u, x_{0}, t_{0}, t_{f}\right)=\int_{t_{0}}^{t_{f}}\left[x^{T}(t) Q(t) x(t)+u^{T}(t) R(t) u(t)\right] d t+x\left(t_{f}\right)^{T} S x\left(t_{f}\right) &amp; \\ st. &amp; \dot{x}=A(t) x+B(t) u(t)\\ \end{matrix}\]</span></p><h2 id="矩阵">矩阵</h2><h3 id="矩阵范数">矩阵范数</h3><p><span class="math display">\[\left \| \mathbf{A} \right \|_{F}=\left ( \sum_{i=1}^{m}\sum_{j=1}^{n}\left ( a_{ij} \right )^{2} \right )^{\frac{1}{2}}\]</span></p><h3 id="线性方程">线性方程</h3><p>假设有矩阵$<span class="math inline">\(\mathbf{A}=\left[\mathbf{a}_{1}, \mathbf{a}_{2}, \ldots, \mathbf{a}_{n}\right]\)</span>，那么就可以用<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>表示一个线性方程。</p><h3 id="内积">内积</h3><p>假设<span class="math inline">\(\mathbf{x}, \mathbf{y} \in \mathbb{R}^{n}\)</span>，那么内积就可以表示为<span class="math inline">\(\left \langle \mathbf{x}, \mathbf{y} \right \rangle=\sum_{i=1}^{n} x_{i} y_{i}=\mathbf{x}^{T} \mathbf{y}\)</span></p><h3 id="特征值和特征矩阵">特征值和特征矩阵</h3><p>令<span class="math inline">\(\mathbf{A}\)</span>是<span class="math inline">\(n \times n\)</span>的矩阵，<span class="math inline">\(\lambda\)</span>是一个标量，<span class="math inline">\(\mathbf{v}\)</span>是一个非0矩阵，如果<span class="math inline">\(\mathbf{Av}=\lambda \mathbf{v}\)</span>，那么<span class="math inline">\(\lambda\)</span>就是特征值，就是特征矩阵。</p><h2 id="几何概念">几何概念</h2><h3 id="线段">线段</h3><p>线段的定义：<span class="math inline">\(\mathbf{z}=\alpha \mathbf{x}+(1-\alpha) \mathbf{y}\)</span>，并且<span class="math inline">\(\alpha \in \left [ 0,1 \right ]\)</span>。</p><h3 id="超平面">超平面</h3><p>假设<span class="math inline">\(u_{1}, u_{2}, \ldots, u_{n}, v \in \mathbb{R}\)</span>，其中至少有一个<span class="math inline">\(u_{i}\)</span>是非零，并且所有点的集合<span class="math inline">\(\mathbf{x}=\left[x_{1}, x_{2}, \ldots, x_{n}\right]^{T}\)</span>组成的线性方程</p><p><span class="math display">\[u_{1} x_{1}+u_{2} x_{2}+\ldots+u_{n} x_{n}=v\]</span></p><p>称为超平面。</p><p>当<span class="math inline">\(n=2\)</span>时，超平面为一条直线。</p><p>当<span class="math inline">\(n=3\)</span>时，超平面为一个平面。</p><p>即超平面为源空间维度的<span class="math inline">\(n-1\)</span>。</p><p>当<span class="math inline">\(u_{1} x_{1}+u_{2} x_{2}+\ldots+u_{n} x_{n} \geq v\)</span>，表示正半空间。<span class="math inline">\(H_{+}=\left\{\mathbf{x} \in \mathbb{R}^{n}: \mathbf{u}^{T} \mathbf{x} \geq v\right\}\)</span>。</p><p>当<span class="math inline">\(u_{1} x_{1}+u_{2} x_{2}+\ldots+u_{n} x_{n} \leq v\)</span>，表示正半空间。<span class="math inline">\(H_{-}=\left\{\mathbf{x} \in \mathbb{R}^{n}: \mathbf{u}^{T} \mathbf{x} \leq v\right\}\)</span>。</p><h3 id="凸集">凸集</h3><p>假设<span class="math inline">\(\Theta \in \mathbb{R}^{n}\)</span>是一个集合，那么如果集合中的任意两个向量<span class="math inline">\(\mathbf{u}\)</span>和<span class="math inline">\(\mathbf{v}\)</span>组成的线段中的点也在集合中，那么该集合为凸集，即<span class="math inline">\(\alpha \mathbf{u}+(1-\alpha) \mathbf{v} \in \Theta\)</span>，且<span class="math inline">\(\alpha \in[0,1]\)</span>。</p><p>凸集的例子：空集、由一个点组成的集合、一条直线和线段、子空间、超平面、半空间、<span class="math inline">\(\mathbb{R}^{n}\)</span>。</p><h3 id="凸包">凸包</h3><p><span class="math inline">\(\textbf{conv} \mathbb{C}=\left \{ \theta_{1} \mathbf{x}_{1}+\cdots+\theta_{k} \mathbf{x}_{k} \mid \mathbf{x}_{i} \in \mathbb{C}, \theta_{i} \geq 0, i=1, \ldots, k,\theta_{1}+\cdots+\theta_{k}=1 \right \}\)</span></p><h3 id="领域">领域</h3><p>点<span class="math inline">\(\mathbf{x} \in \mathbb{R}^{n}\)</span>的邻域可以定义为<span class="math inline">\(\left\{\mathbf{y} \in \mathbb{R}^{n}:\|\mathbf{y}-\mathbf{x}\|&lt;\varepsilon\right\}\)</span>，其中<span class="math inline">\(\varepsilon\)</span>为正值。</p><h2 id="微积分">微积分</h2><p>1、给定<span class="math inline">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>，那么<span class="math inline">\(f\)</span>的梯度是一个函数<span class="math inline">\(\nabla f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}\)</span>，记作<span class="math inline">\(\nabla f(\mathbf{x})=\left[\begin{array}{c}{\frac{\partial f}{\partial x_{1}}(\mathbf{x})} \\ {\vdots} \\ {\frac{\partial f}{\partial x_{n}}(\mathbf{x})}\end{array}\right]\)</span>，其中<span class="math inline">\(\nabla f(\mathbf{x})\)</span>是一个在<span class="math inline">\(\mathbb{R}^{n}\)</span>中的向量，记作<span class="math inline">\(\nabla f(\mathbf{x})=D f(\mathbf{x})^{\top}\)</span>。</p><p>2、给定<span class="math inline">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\)</span>，<span class="math inline">\(f=\left[f_{1}, \ldots, f_{m}\right]^{\top}\)</span>，那么<span class="math inline">\(f\)</span>的微分方程<span class="math inline">\(D f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m \times n}\)</span>为<span class="math inline">\(D f(x)=\left[\begin{array}{ccc}{\frac{\partial f_{1}}{\partial x_{1}}(\mathbf{x})} &amp; {\dots} &amp; {\frac{\partial f_{1}}{\partial x_{n}}(\mathbf{x})} \\ {\vdots} &amp; {} &amp; {\vdots} \\ {\frac{\partial f_{m}}{\partial x_{1}}(\mathbf{x})} &amp; {\cdots} &amp; {\frac{\partial f_{m}}{\partial x_{n}}(\mathbf{x})}\end{array}\right]\)</span>。</p><p>3、如果<span class="math inline">\(f\)</span>是二阶可微，那么<span class="math inline">\(\mathbf{F}=D^{2} f=\left[\begin{array}{cccc}{\frac{\partial^{2} f}{\partial x_{1}^{2}}} &amp; {\frac{\partial^{2} f}{\partial x_{2} \partial x_{1}}} &amp; {\cdots} &amp; {\frac{\partial^{2} f}{\partial x_{n} \partial x_{1}}} \\ {\frac{\partial^{2} f}{\partial x_{1} \partial x_{2}}} &amp; {\frac{\partial^{2} f}{\partial x_{2}^{2}}} &amp; {\cdots} &amp; {\frac{\partial^{2} f}{\partial x_{n} \partial x_{1}}} \\ {\vdots} &amp; {\vdots} &amp; {\ddots} &amp; {\vdots} \\ {\frac{\partial^{2} f}{\partial x_{1} \partial x_{n}}} &amp; {\frac{\partial^{2} f}{\partial x_{2} \partial x_{n}}} &amp; {\cdots} &amp; {\frac{\partial^{2} f}{\partial x_{n}^{2}}}\end{array}\right]\)</span>，该矩阵称为<span class="math inline">\(f\)</span>的黑塞矩阵（Hessian）。</p><h2 id="水平集和梯度">水平集和梯度</h2><p><span class="math inline">\(\nabla f\left(\mathbf{x}_{0}\right)\)</span>是<span class="math inline">\(f\)</span>在<span class="math inline">\(\mathbf{x}_{0}\)</span>点处最大增长率方向。</p><h1 id="无约束优化问题">无约束优化问题</h1><h2 id="局部极小点x">局部极小点x</h2><p><span class="math inline">\(\mathbf{x}^{\ast}\)</span>是局部极小点的条件是<span class="math inline">\(\nabla f\left(\mathbf{x}^{\ast}\right)=0\)</span>。</p><h2 id="可行方向">可行方向</h2><p>如果存在<span class="math inline">\(\alpha_{0}&gt;0\)</span>，并且满足<span class="math inline">\(\alpha \in\left[0, \alpha_{0}\right]\)</span>，使得<span class="math inline">\(\mathbf{x}+\alpha \mathbf{d} \in \Omega\)</span>，那么<span class="math inline">\(\mathbf{d} \in \mathbb{R}^{n}, \mathbf{d} \neq 0\)</span>就是<span class="math inline">\(\mathbf{x} \in \Omega\)</span>中的可行方向。</p><h3 id="方向导数">方向导数</h3><p>当可行方向<span class="math inline">\(\mathbf{d}\)</span>是单位向量时，那么函数<span class="math inline">\(f\)</span>在<span class="math inline">\(\mathbf{x}\)</span>处沿方向<span class="math inline">\(\mathbf{d}\)</span>的增长率可以用内积表示，即<span class="math inline">\(\frac{\partial f}{\partial \mathbf{d}}(\mathbf{x})=\mathbf{d}^{\top} \nabla f(\mathbf{x})=\nabla f(\mathbf{x})^{\top} \mathbf{d}=\left \langle \nabla f(\mathbf{x}), \mathbf{d} \right \rangle\)</span>。</p><h3 id="fonc一阶必要条件">FONC（一阶必要条件）</h3><p>如果<span class="math inline">\(\mathbf{x}^{\ast}\)</span>是函数<span class="math inline">\(f\)</span>在<span class="math inline">\(\Omega\)</span>上的局部极小点，那么对于<span class="math inline">\(\mathbf{x}^{\ast}\)</span>处的任意可行方向<span class="math inline">\(\mathbf{d}\)</span>都有<span class="math inline">\(\mathbf{d}^{T} \nabla f\left(\mathbf{x}^{\ast}\right) \geq 0\)</span>。</p><h3 id="sonc二阶必要条件">SONC（二阶必要条件）</h3><p>如果<span class="math inline">\(f\)</span>在约束集<span class="math inline">\(\Omega\)</span>上二阶连续可导，并且<span class="math inline">\(\mathbf{x}^{\ast}\)</span>是函数<span class="math inline">\(f\)</span>在<span class="math inline">\(\Omega\)</span>上的局部极小点，<span class="math inline">\(\mathbf{d}\)</span>是<span class="math inline">\(\mathbf{x}^{\ast}\)</span>处的可行方向，并且<span class="math inline">\(\mathbf{d}^{T} \nabla f\left(\mathbf{x}^{\ast}\right) = 0\)</span>，则<span class="math inline">\(\mathbf{d}^{T} F\left(\mathbf{x}^{\ast}\right) \mathbf{d} \geq 0\)</span>，其中<span class="math inline">\(F\)</span>为函数<span class="math inline">\(f\)</span>的黑塞矩阵。</p><h3 id="sosc二阶充分条件">SOSC（二阶充分条件）</h3><p>如果<span class="math inline">\(f\)</span>在约束集<span class="math inline">\(\Omega\)</span>上二阶连续可导，如果同时满足<span class="math inline">\(\nabla f\left(\mathbf{x}^{\ast}\right)=0\)</span>和<span class="math inline">\(F\left(\mathbf{x}^{\ast}\right)&gt;0\)</span>，那么<span class="math inline">\(\mathbf{X}^{\ast}\)</span>为严格局部极小点。</p><h1 id="一维搜索方法">一维搜索方法</h1><h2 id="介绍-1">介绍</h2><p>该方法主要使用迭代搜索算法或线搜法，基本流程是：</p><blockquote><ul><li>1、赋一个初值<span class="math inline">\(x^{\left ( 0 \right )}\)</span>。</li><li>2、生成迭代序列<span class="math inline">\(x^{\left ( 1 \right )},x^{\left ( 2 \right )},\cdots\)</span>。</li><li>3、每次迭代，下一个<span class="math inline">\(x^{\left ( k+1 \right )}\)</span>依赖于上一个<span class="math inline">\(x^{\left ( k \right )}\)</span>。</li></ul></blockquote><p>目标函数<span class="math inline">\(f\)</span>，一阶导数<span class="math inline">\({f}&#39;\)</span>，二阶导数<span class="math inline">\({f}&#39;&#39;\)</span>。</p><p>常用的一维搜索算法：</p><blockquote><ul><li>1、黄金分割法。（只使用目标函数<span class="math inline">\(f\)</span>）</li><li>2、斐波那契数列方法。（只使用目标函数<span class="math inline">\(f\)</span>）</li><li>3、二分法。（只使用目标函数的一阶导数<span class="math inline">\({f}&#39;\)</span>）</li><li>4、割线法。（只使用目标函数的一阶导数<span class="math inline">\({f}&#39;\)</span>）</li><li>5、牛顿法。（只使用目标函数的一阶导数<span class="math inline">\({f}&#39;\)</span>和二阶导数<span class="math inline">\({f}&#39;&#39;\)</span>）</li></ul></blockquote><h2 id="泰勒公式">泰勒公式</h2><p>泰勒公式是许多数值方法和优化模型的基础。</p><p>假设<span class="math inline">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span>在区间<span class="math inline">\([a, b]\)</span>上是<span class="math inline">\(m\)</span>次连续可微函数。假设<span class="math inline">\(h=[b-a]\)</span>，那么<span class="math inline">\(f\)</span>的第<span class="math inline">\(i\)</span>阶导数<span class="math inline">\(f^{(i)}\)</span>为</p><p><span class="math display">\[f(b)=f(a)+\frac{h}{1 !} f^{(1)}(a)+\frac{h^{2}}{2 !} f^{(2)}(a)+\ldots+\frac{h^{m-1}}{(m-1) !} f^{(m-1)}(a)+R_{m}\]</span></p><p>其中<span class="math inline">\(R_{m}\)</span>为余项</p><p><span class="math display">\[R_{m}=\frac{h^{m}(1-\theta)^{m-1}}{(m-1) !} f^{(m)}(a+\theta h)=\frac{h^{m}}{m !}\left(a+\theta^{\prime} h\right)\]</span></p><p>其中<span class="math inline">\(\theta, \theta^{\prime} \in(0,1)\)</span>。</p><h2 id="牛顿法牛顿切线法">牛顿法（牛顿切线法）</h2><p>牛顿法主要有两方面的应用</p><p>1、求方程根：使用一阶导数求实值函数的根。</p><p>2、优化：使用一阶和二阶导数求一个实值函数优化器的逼近。</p><blockquote><p>1、目标：</p></blockquote><p>求<span class="math inline">\(x^{\ast}\)</span>，使得<span class="math inline">\(g\left(x^{\ast}\right)=0\)</span></p><blockquote><p>2、核心思想：</p></blockquote><p>基于泰勒公式展开，构建新的函数来逼近原函数。</p><p><span class="math display">\[f(x)=g\left(x_{0}\right)+\left(x-x_{0}\right) g^{\prime}\left(x_{0}\right)\]</span></p><p>由于<span class="math inline">\(f(x)\)</span>是<span class="math inline">\(g\left(x\right)\)</span>的近似。因此，要求的<span class="math inline">\(f(x)\)</span>极小点，那么就要满足一阶必要条件，即<span class="math inline">\(f(x)=0\)</span>，那么上式就可以得到</p><p><span class="math display">\[x=x_{0}-\frac{g\left(x_{0}\right)}{g^{\prime}\left(x_{0}\right)}\]</span></p><p>从而得到整个迭代过程为</p><p><span class="math display">\[x_{k+1}=x_{k}-\frac{g\left(x_{k}\right)}{g^{\prime}\left(x_{k}\right)}\]</span></p><blockquote><p>3、几何角度</p></blockquote><p>几何上来说，就是找到<span class="math inline">\(x^{\left ( k \right )}\)</span>出的切线与<span class="math inline">\(x\)</span>轴的交点作为<span class="math inline">\(x^{\left ( k+1 \right )}\)</span>，然后再以<span class="math inline">\(x^{\left ( k+1 \right )}\)</span>点的切线找到<span class="math inline">\(x^{\left ( k+2 \right )}\)</span>，一次类推最终逼近极值点。</p><blockquote><p>4、注意事项</p></blockquote><p>如果<span class="math inline">\(\frac{g\left(x_{k}\right)}{g^{\prime}\left(x_{k}\right)}\)</span>的比值不是足够小时，牛顿法可能就会失效，因为会错过极小值，所以初始点的选择很重要。</p><h2 id="牛顿优化法">牛顿优化法</h2><p>构建一个在<span class="math inline">\(x^{(k)}\)</span>点的原函数、一阶函数和二界函数，并且构建一个逼近于原函数<span class="math inline">\(f(x)\)</span>的近似函数</p><p><span class="math display">\[q(x)=f\left(x^{(k)}\right)+f^{\prime}\left(x^{(k)}\right)\left(x-x^{(k)}\right)+\frac{1}{2} f^{\prime \prime}\left(x^{(k)}\right)\left(x-x^{(k)}\right)^{2}\]</span></p><p>其中<span class="math inline">\(q(x)\)</span>与<span class="math inline">\(f(x)\)</span>的一阶和二阶导数相比配</p><p><span class="math inline">\(q\left(x^{(k)}\right)=f\left(x^{(k)}\right)\)</span></p><p><span class="math inline">\(q^{\prime}\left(x^{(k)}\right)=f^{\prime}\left(x^{(k)}\right)\)</span></p><p><span class="math inline">\(q^{\prime \prime}\left(x^{(k)}\right)=f^{\prime \prime}\left(x^{(k)}\right)\)</span></p><p>原先去<span class="math inline">\(f\)</span>的最小值，现在去近似函数<span class="math inline">\(q\)</span>的最小值。</p><p>按照一阶必要条件（FONC）可以得到</p><p><span class="math display">\[q^{\prime}(x)=f^{\prime}\left(x^{(k)}\right)+f^{\prime \prime}\left(x^{(k)}\right)\left(x-x^{(k)}\right)=0\]</span></p><p>令<span class="math inline">\(x=x^{(k+1)}\)</span>，那么就可以得到</p><p><span class="math display">\[x^{(k+1)}=x^{(k)}-\frac{f^{\prime}\left(x^{(k)}\right)}{f^{\prime \prime}\left(x^{(k)}\right)}\]</span></p><p>注意，对于区间内任何<span class="math inline">\(x\)</span>都有<span class="math inline">\(f^{\prime \prime}(x)&gt;0\)</span>，那么牛顿法能正常工作，但如果对于一些<span class="math inline">\(x\)</span>造成<span class="math inline">\(f^{\prime \prime}(x)&lt;0\)</span>，那么牛顿法可能就会收敛到极大点，而不是极小点。</p><h2 id="割线法">割线法</h2><p>如果函数二阶不可导，那么二阶导数就可以近似为</p><p><span class="math display">\[f^{\prime \prime}\left(x^{(k)}\right) \approx \frac{f^{\prime}\left(x^{(k)}\right)-f^{\prime}\left(x^{(k-1)}\right)}{x^{(k)}-x^{(k-1)}}\]</span></p><p>因此，就可以得到割线法公式</p><p><span class="math display">\[x^{(k+1)}=x^{(k)}-\frac{x^{(k)}-x^{(k-1)}}{f^{\prime}\left(x^{(k)}\right)-f^{\prime}\left(x^{(k-1)}\right)} f^{\prime}\left(x^{(k)}\right)\]</span></p><p>该方法需要有两个初始值，分别是<span class="math inline">\(x^{(k)}\)</span>和<span class="math inline">\(x^{(k-1)}\)</span>。</p><h2 id="多维优化问题中的一维搜索">多维优化问题中的一维搜索</h2><p>一维搜索方法在多维优化问题中扮演非常重要的角色。特别是对于多维优化问题的迭代求解算法，通常每次迭代都会包括一维搜索过程。</p><p>令目标函数<span class="math inline">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>，寻找<span class="math inline">\(f\)</span>极小值的迭代算法为</p><p><span class="math display">\[\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}+\alpha_{k} \mathbf{d}^{(k)}\]</span></p><p>其中<span class="math inline">\(\mathbf{x}^{(0)}\)</span>为给定的初始点，<span class="math inline">\(\alpha_{k} \geq 0\)</span>为步长，其确定方式为使下面函数最小</p><p><span class="math display">\[\phi_{k}(\alpha)=f\left(\mathbf{x}^{(k)}+\alpha \mathbf{d}^{(k)}\right)\]</span></p><p>其中<span class="math inline">\(\mathbf{d}\)</span>为搜索方向。通过一维搜索确定<span class="math inline">\(\alpha_{k}\)</span>后，可以使得<span class="math inline">\(f\left(\mathbf{x}^{(k+1)}\right) &lt; f\left(\mathbf{x}^{(k)}\right)\)</span>。</p><h1 id="梯度方法">梯度方法</h1><p>常用的梯度方法</p><blockquote><p>梯度下降</p></blockquote><blockquote><ul><li>1、固定步长的梯度下降</li><li>2、最速梯度下降</li><li>3、随机梯度下降</li></ul></blockquote><blockquote><p>共轭梯度</p></blockquote><h2 id="介绍-2">介绍</h2><p>因为<span class="math inline">\(\mathbf{d}=\nabla f(\mathbf{x})\)</span>是增长率最大的方向，因此<span class="math inline">\(\mathbf{d}=-\nabla f(\mathbf{x})\)</span>就是下降最快的方向。</p><p>梯度下降算法的核心实现：</p><p><span class="math display">\[\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}-\alpha_{k} \nabla f\left(\mathbf{x}^{(k)}\right)\]</span></p><p>其中<span class="math inline">\(\alpha_{k}\)</span>是步长，<span class="math inline">\(\nabla f\left(\mathbf{x}^{(k)}\right)\)</span>是方向。</p><p>1、<span class="math inline">\(\alpha_{k}\)</span>选择的影响：</p><blockquote><p>当<span class="math inline">\(\alpha_{k}\)</span>太小，那么迭代的次数就会变多。</p></blockquote><blockquote><p>当<span class="math inline">\(\alpha_{k}\)</span>太大，那么就会在最优点之间来回震荡。</p></blockquote><p>2、<span class="math inline">\(\alpha_{k}\)</span>的选择有许多方法：</p><blockquote><p>可以在每次迭代中使<span class="math inline">\(\alpha_{k}\)</span>固定，也可以让<span class="math inline">\(\alpha_{k}\)</span>随迭代变化而变化。</p></blockquote><blockquote><p>动态计算<span class="math inline">\(\alpha_{k}\)</span></p></blockquote><p><span class="math display">\[\alpha_{k}=\arg \min _{\alpha \geq 0} f\left(\mathbf{x}^{(\mathbf{k})}-\alpha \nabla f\left(\mathbf{x}^{(k)}\right)\right)\]</span></p><h2 id="最速下降法">最速下降法</h2><blockquote><p>该方法时一个梯度法。</p></blockquote><blockquote><p>选择步长以实现目标函数在每个单独步骤中的最大减少量。</p></blockquote><p><span class="math display">\[\alpha_{k}=\arg \min _{\alpha \geq 0} f\left(\mathbf{x}^{(\mathbf{k})}-\alpha \nabla f\left(\mathbf{x}^{(\mathbf{k})}\right)\right)\]</span></p><p>最速下降法的基本过程：x</p><blockquote><ul><li>1、每一步以<span class="math inline">\(\mathbf{x}^{(\mathbf{k})}\)</span>开始。</li><li>2、通过线搜法沿着方向<span class="math inline">\(-\nabla f\left(\mathbf{x}^{(\mathbf{k})}\right)\)</span>获取最小的<span class="math inline">\(\mathbf{x}^{(\mathbf{k}+\mathbf{1})}\)</span>。</li></ul></blockquote><p>在最速下降法中，假如<span class="math inline">\(\left\{\mathbf{x}^{(\mathbf{k})}\right\}_{k=0}^{\infty}\)</span>是每次迭代得到的值，那么对于每个<span class="math inline">\(k\)</span>，都有<span class="math inline">\(\mathbf{x}^{(\mathbf{k}+\mathbf{1})}-\mathbf{x}^{(\mathbf{k})}\)</span>与<span class="math inline">\(\mathbf{x}^{(\mathbf{k}+2)}-\mathbf{x}^{(\mathbf{k}+1)}\)</span>正交。</p><p>当<span class="math inline">\(\mathbf{x}^{(\mathbf{k}+\mathbf{1})}=\mathbf{x}^{(\mathbf{k})}\)</span>，那么这种情况就是算法停止的条件。</p><blockquote><p>梯度收敛的总结</p></blockquote><p>1、如果目标函数<span class="math inline">\(f\)</span>是凸的，则通过满足Wolfe条件的线搜索来选择步长，则相应的梯度法是全局收敛的。</p><p>2、如果目标函数是二次型<span class="math inline">\(f(\mathbf{x})=\frac{1}{2} \mathbf{x}^{T} Q \mathbf{x}-\mathbf{b}^{T} \mathbf{x}\)</span>，并且<span class="math inline">\(Q\)</span>是正定的，那么最速梯度法是全局收敛。</p><p>3、如果目标函数是二次型<span class="math inline">\(f(\mathbf{x})=\frac{1}{2} \mathbf{x}^{T} Q \mathbf{x}-\mathbf{b}^{T} \mathbf{x}\)</span>，并且<span class="math inline">\(Q\)</span>是正定的，那么固定步长梯度法也是全局收敛，并且<span class="math inline">\(0&lt;\alpha&lt;\frac{2}{\lambda_{\max }(Q)}\)</span>。</p><p>给定一个序列<span class="math inline">\(\left\{\mathbf{x}^{(k)}\right\}\)</span>，该序列收敛到<span class="math inline">\(\mathbf{x}^{\ast}\)</span>。当<span class="math inline">\(\lim _{k \rightarrow \infty}\left\|\mathbf{x}^{(k)}-\mathbf{x}^{*}\right\|=0\)</span>时，那么收敛的阶数是<span class="math inline">\(p\)</span>，并且<span class="math inline">\(p \in \mathbb{R}\)</span>。</p><p>当<span class="math inline">\(p=1\)</span>（一阶收敛），并且<span class="math inline">\(\lim _{k \rightarrow \infty} \frac{\left\|\mathbf{x}^{(k+1)}-\mathbf{x}^{*}\right\|}{\left\|\mathbf{x}^{(k)}-\mathbf{x}^{*}\right\|^{p}}=1\)</span>，那么收敛是次线性的。</p><p>当<span class="math inline">\(p=1\)</span>（一阶收敛），并且<span class="math inline">\(\lim _{k \rightarrow \infty} \frac{\left\|\mathbf{x}^{(k+1)}-\mathbf{x}^{*}\right\|}{\left\|\mathbf{x}^{(k)}-\mathbf{x}^{*}\right\|^{p}}&lt;1\)</span>，那么收敛是线性的。</p><p>当<span class="math inline">\(p&gt;1\)</span>，那么收敛是超线性的。</p><p>当<span class="math inline">\(p=2\)</span>（二阶收敛），那么收敛是二次型的。</p><p>当<span class="math inline">\(p=3\)</span>（三阶收敛），那么收敛是立方的。</p><blockquote><p>例子</p></blockquote><p>假设<span class="math inline">\(x^{\left ( k \right )}=\frac{1}{k}\)</span>，并且<span class="math inline">\(x^{\left ( k \right )} \rightarrow 0\)</span>，那么<span class="math inline">\(\frac{\left|x^{(k+1)}\right|}{\left|x^{(k)}\right|^{p}}=\frac{\frac{1}{k+1}}{\frac{1}{k^{p}}}=\frac{k^{p}}{k+1}\)</span></p><p>当<span class="math inline">\(p &gt; 1\)</span>时，上式趋近于<span class="math inline">\(\infty\)</span>。</p><p>当<span class="math inline">\(p &lt; 1\)</span>时，上式收敛到0。</p><p>当<span class="math inline">\(p = 1\)</span>时，上式收敛到1。</p><p>因此，收敛的阶数为1。</p><h1 id="牛顿法">牛顿法</h1><h2 id="基本思想">基本思想</h2><p>1、给定一个初值点。</p><p>2、构造目标函数的二次逼近，该目标函数与该点上的第一和第二导数值相匹配。</p><p>3、最小化近似二次函数代替原来的目标函数。</p><p>4、使用近似函数的极小值作为起点，迭代地重复该过程。</p><h2 id="牛顿法没有步阶大小或者步阶为1">牛顿法（没有步阶大小，或者步阶为1）</h2><p>1、给定<span class="math inline">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>，并且当前迭代为<span class="math inline">\(\mathbf{x}^{(k)}\)</span>。</p><p>2、通过二次型近似函数<span class="math inline">\(f\)</span>求<span class="math inline">\(\mathbf{x}^{(k+1)}\)</span>。</p><p><span class="math display">\[q(\mathbf{x})=f\left(\mathbf{x}^{(k)}\right)+\left(\mathbf{x}-\mathbf{x}^{(k)}\right)^{\top} \mathbf{g}^{(k)}+\frac{1}{2}\left(\mathbf{x}-\mathbf{x}^{(k)}\right)^{\top} \mathbf{F}\left(\mathbf{x}^{(k)}\right)\left(\mathbf{x}-\mathbf{x}^{(k)}\right)\]</span></p><p>3、最小化<span class="math inline">\(q\)</span>来迭代下一个<span class="math inline">\(\mathbf{x}^{(k+1)}\)</span>。</p><p>4、假设<span class="math inline">\(\mathbf{g}^{(k)}=\nabla f\left(\mathbf{x}^{(k)}\right)\)</span>。通过一阶必要条件，可以知道<span class="math inline">\(\nabla q\left(\mathbf{x}^{(k)}\right)=0\)</span>。</p><p><span class="math display">\[\nabla q\left(\mathbf{x}^{(k)}\right)=\mathbf{g}^{(k)}+\mathbf{F}\left(\mathbf{x}^{(k)}\right)\left(\mathbf{x}-\mathbf{x}^{(k)}\right)=0\]</span></p><p>5、牛顿算法</p><p><span class="math display">\[\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}-\mathbf{F}\left(\mathbf{x}^{(k)}\right)^{-1} \mathbf{g}^{(k)}\]</span></p><p>搜索方向</p><p><span class="math display">\[\mathbf{d}^{(k)}=-\mathbf{F}\left(\mathbf{x}^{(k)}\right)^{-1} \mathbf{g}^{(k)}=\mathbf{x}^{(k+1)}-\mathbf{x}^{(k)}\]</span></p><h2 id="levenberg-marquardt修正">Levenberg-Marquardt修正</h2><p>如果黑塞矩阵<span class="math inline">\(\mathbf{F}\left(\mathbf{x}^{(k)}\right)\)</span>不正定，那么搜索方向就会使下降方向<span class="math inline">\(\mathbf{d}^{(k)}=-\mathbf{F}\left(\mathbf{x}^{(k)}\right)^{-1} \mathbf{g}^{(k)}\)</span>可能不会是下降方向，因此Levenberg-Marquardt修正解决了这个问题。</p><p><span class="math display">\[\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}-\alpha_{k}\left(\mathbf{F}\left(\mathbf{x}^{(k)}\right)+\mu_{k} \mathbf{I}\right)^{-1} \mathbf{g}^{(k)}\]</span></p><p>其中<span class="math inline">\(\mu_{k} \geq 0\)</span>，<span class="math inline">\(F\)</span>为对称矩阵。</p><p>1、<span class="math inline">\(\mu_{k} \rightarrow 0\)</span>：Levenberg-Marquardt修正逐步接近牛顿法。</p><p>2、<span class="math inline">\(\mu_{k} \rightarrow \infty\)</span>：Levenberg-Marquardt修正表现出步长较小时的梯度方法的特征。</p><p>实际应用中，<span class="math inline">\(\mu_{k}\)</span>的初始值较小，然后逐步增加，直到出现下降特征，即<span class="math inline">\(f\left ( \mathbf{x}^{k+1} \right ) &lt; f\left ( \mathbf{x}^{k} \right )\)</span>为止。</p><h2 id="牛顿法总结">牛顿法总结</h2><p>1、如果起始点与最小值足够近，牛顿法的效果会很好。</p><p>2、可以合并一个步长以确保下降</p><p>3、对于二次型，一步收敛。</p><h1 id="共轭方向法">共轭方向法</h1><h2 id="介绍-3">介绍</h2><p>共轭方向法的效率和计算复杂度位于最速下降法和牛顿法之间。</p><p>共轭方向法有如下特征：</p><p>1、对于<span class="math inline">\(n\)</span>维二次型问题，能够在<span class="math inline">\(n\)</span>步内得到结果。</p><p>2、共轭方向法的典型代表共轭梯度法不需要计算黑塞矩阵。</p><p>3、不需要存储<span class="math inline">\(n \times n\)</span>矩阵，也不需要求逆。</p><p>4、比最速下降法复杂。</p><p>通常情况下比最速下降法性能更好，但不如牛顿法。迭代搜索方法效率的关键因素是每次迭代的搜索方向。对于某些函数，最佳搜索方向是Q-共轭方向。</p><h2 id="共轭向量">共轭向量</h2><p>1、给定对称举证<span class="math inline">\(\mathbf{Q} \in \mathbb{R}^{n \times n}\)</span>。</p><p>2、如果两个向量<span class="math inline">\(\mathbf{d}(1)\)</span>和<span class="math inline">\(\mathbf{d}(2)\)</span>是Q共轭，那么<span class="math inline">\(\mathbf{d}^{(1) \top} \mathbf{Q} \mathbf{d}^{(2)}=0\)</span>。</p><p>3、假设<span class="math inline">\(\mathbf{Q}\)</span>是对称<span class="math inline">\({n \times n}\)</span>举证，那么对于方向<span class="math inline">\(\mathbf{d}^{(0)}, \mathbf{d}^{(1)}, \mathbf{d}^{(2)}, \ldots, \mathbf{d}^{(m)}\)</span>如果是Q共轭的话，那么对于所有<span class="math inline">\(i \neq j\)</span>都有<span class="math inline">\(\mathbf{d}^{(i) \top} \mathbf{Q} \mathbf{d}^{(j)}=0\)</span>。</p><p>4、如果<span class="math inline">\(\mathbf{Q}=\mathbf{I}\)</span>，那么共轭变为正交。</p><h2 id="共轭方向算法">共轭方向算法</h2><p>考虑算法<span class="math inline">\(\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}+\alpha_{k} \mathbf{d}^{(k)}\)</span>，其中<span class="math inline">\(\alpha_{k}=\arg \min _{\alpha \geq 0} f\left(\mathbf{x}^{(k)}+\alpha \mathbf{d}^{(k)}\right)\)</span>。</p><p>应用到二次型则是<span class="math inline">\(f(\mathbf{x})=\frac{1}{2} \mathbf{x}^{\top} \mathbf{Q} \mathbf{x}-\mathbf{x}^{T} \mathbf{b}\)</span>，其中<span class="math inline">\(\mathbf{Q}=\mathbf{Q}^{\top} &gt; 0\)</span>。</p><p>如果给定起始点<span class="math inline">\(\mathbf{x}^{\left ( 0 \right )}\)</span>，和一组关于<span class="math inline">\(\mathbf{Q}\)</span>的共轭方向<span class="math inline">\(\mathbf{d}^{(0)}, \mathbf{d}^{(1)}, \ldots, \mathbf{d}^{(n-1)}\)</span>，那么迭代公式为（<span class="math inline">\(k \geq 0\)</span>表示迭代次数）：</p><p><span class="math display">\[\mathbf{g}^{\left ( k \right )}=\nabla f\left ( \mathbf{x}^{k} \right )=\mathbf{Q}\mathbf{x}^{\left ( k \right )}-\mathbf{b}\]</span></p><p><span class="math display">\[\alpha_{k}=-\frac{\mathbf{g}^{(k) \top} \mathbf{d}^{(k)}}{\mathbf{d}^{(k) \top} \mathbf{Q} \mathbf{d}^{(k)}}\]</span></p><p><span class="math display">\[\mathbf{x}^{\left ( k+1 \right )}=\mathbf{x}^{\left ( k \right )}+\alpha_{k}\mathbf{d}^{\left ( k \right )}\]</span></p><p>对于二次型来说，共轭方向算法有如下优势：对于任意的起始点<span class="math inline">\(\mathbf{x}^{(0)}\)</span>，基本的共轭方向算法都能在<span class="math inline">\(n\)</span>次迭代之内收敛到唯一的全局极小点<span class="math inline">\(\mathbf{x}^{\star}\)</span>，即<span class="math inline">\(\mathbf{x}^{(n)}=\mathbf{x}^{\star}\)</span>。</p><h2 id="共轭梯度法">共轭梯度法</h2><p>1、共轭梯度法在计算过程中计算方向。</p><p>2、在每个迭代，搜索方向方向都是前一个搜索方向和当前梯度的线性组合。</p><p>3、使其与前面产生的搜索方向组成<span class="math inline">\(\mathbf{Q}\)</span>共轭方向。</p><blockquote><p>算法流程</p></blockquote><p>1、考虑二次型目标函数：<span class="math inline">\(f(\mathbf{x})=\frac{1}{2} \mathbf{x}^{\top} \mathbf{Q} \mathbf{x}-\mathbf{x}^{\top} \mathbf{b}, \mathbf{x} \in \mathbb{R}\)</span></p><p>2、起始点<span class="math inline">\(\mathbf{x}^{(0)}\)</span>，搜索方向采用最速下降法的方向，即函数<span class="math inline">\(f\)</span>在<span class="math inline">\(\mathbf{x}^{(0)}\)</span>处的梯度负方向：<span class="math inline">\(\mathbf{d}^{(0)}=-\mathbf{g}^{(0)}\)</span>。</p><p>3、因此<span class="math inline">\(\mathbf{x}^{(1)}=\mathbf{x}^{(0)}+\alpha_{0} \mathbf{d}^{(0)}\)</span>，并且<span class="math inline">\(\alpha_{0}=\arg \min _{\alpha \geq 0} f\left(\mathbf{x}^{(0)}+\alpha \mathbf{d}^{(0)}\right)=-\frac{\mathbf{g}^{(0) \top} \mathbf{d}^{(0)}}{\mathbf{d}^{(0) \top} \mathbf{Q} \mathbf{d}^{(0)}}\)</span>。</p><p>4、接下来，搜索方向<span class="math inline">\(\mathbf{d}^{(1)}\)</span>应该和<span class="math inline">\(\mathbf{d}^{(0)}\)</span>关于<span class="math inline">\(\mathbf{Q}\)</span>共轭。</p><p>5、将<span class="math inline">\(\mathbf{d}^{(1)}\)</span>写成<span class="math inline">\(\mathbf{g}^{(1)}\)</span>和<span class="math inline">\(\mathbf{d}^{(0)}\)</span>的线性组合：<span class="math inline">\(\mathbf{d}^{(1)}=-\mathbf{g}^{(1)}+\beta_{0} \mathbf{d}^{(0)}\)</span>。</p><p>6、<span class="math inline">\(\beta_{k}\)</span>可以使<span class="math inline">\(\mathbf{d}^{(k+1)}\)</span>和<span class="math inline">\(\mathbf{d}^{(0)}, \mathbf{d}^{(1)}, \ldots, \mathbf{d}^{(k)}\)</span>组成<span class="math inline">\(\mathbf{Q}\)</span>共轭方向：<span class="math inline">\(\beta_{k}=\frac{\mathbf{g}^{(k+1) \top} \mathbf{Q} \mathbf{d}^{(k)}}{\mathbf{d}^{(k) \top} \mathbf{Q} \mathbf{d}^{(k)}}\)</span>。</p><blockquote><p>三种修正公式，将<span class="math inline">\(\mathbf{Q}\)</span>从<span class="math inline">\(\beta\)</span>计算中消除</p></blockquote><p>1、Hestenes-Stiefel公式：<span class="math inline">\(\beta_{k}=\frac{\mathbf{g}^{(k+1) \top}\left[\mathbf{g}^{(k+1)-\mathbf{g}^{(k)}}\right]}{\mathbf{d}^{(k) \top}\left[\mathbf{g}^{(k+1)}-\mathbf{g}^{(k)}\right]}\)</span></p><p>2、Polak-Ribiere公式：<span class="math inline">\(\beta_{k}=\frac{\mathrm{g}^{(k+1) \top}\left[\mathrm{g}^{(k+1)}-\mathrm{g}(k)\right]}{\mathrm{g}^{(k+1) \top} \mathrm{g}^{(k)}}\)</span></p><p>3、Fletcher-Reeves公式：<span class="math inline">\(\beta_{k}=\frac{\mathbf{g}^{(k+1) \top} \mathbf{g}^{(k+1)}}{\mathbf{g}^{(k) \top} \mathbf{g}^{(k)}}\)</span></p><h3 id="共轭梯度法在非二次型问题">共轭梯度法在非二次型问题</h3><p>假如<span class="math inline">\(f\)</span>是二次型，那么上面三个修正公式等价，如果不是二次型，那么算法不能在<span class="math inline">\(n\)</span>步内进行收敛，并且随着迭代的进行搜索方向将不与<span class="math inline">\(\mathbf{Q}\)</span>共轭。常用的解决方法是经过<span class="math inline">\(n\)</span>或<span class="math inline">\(n+1\)</span>次迭代后，重新将搜索方向初始化为目标函数梯度的负方向，然后继续搜索知道满足停止规则。</p><p>对于非二次型目标函数中，一维搜索精度非常重要，并且一维搜索精度是共轭梯度法性能的关键，如果采用不精确的一维搜索方法，那么建议使用Hestenes-Stiefel公式。</p><p>Powell公式（Polak-Ribiere公式修正）</p><p><span class="math display">\[\beta_{k}=\max \left[0, \frac{\mathbf{g}^{(k+1) \top}\left[\mathbf{g}^{(k+1)} - \mathbf{g}^{(k)}\right]}{\mathbf{g}^{(k) \top} \mathbf{g}^{(k)}}\right]\]</span></p><h1 id="拟牛顿法">拟牛顿法</h1><h2 id="回顾牛顿法">回顾牛顿法</h2><p>牛顿法</p><p><span class="math display">\[\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}-F\left(\mathbf{x}^{(k)}\right)^{-1} \mathbf{g}^{(k)}\]</span></p><p>保证下降性能的改进</p><p><span class="math display">\[\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}-\alpha_{k} F\left(\mathbf{x}^{(k)}\right)^{-1} \mathbf{g}^{(k)}\]</span></p><p>且</p><p><span class="math display">\[\alpha_{k}=\arg \min _{\alpha \geq 0} f\left(\mathbf{x}^{(k)}-\alpha F\left(\mathbf{x}^{(k)}\right)^{-1} \mathbf{g}^{(k)}\right)\]</span></p><p>牛顿法特性：</p><p>1、如果起始点足够接近最小值，那么牛顿法就会快速收敛。</p><p>2、需要计算黑塞矩阵的逆。</p><h2 id="基本思想-1">基本思想</h2><p>1、拟牛顿法：只是用梯度来近似黑塞逆。</p><p>2、使用<span class="math inline">\(\mathbf{H}_{k}\)</span>来代替原先牛顿算法中的黑塞逆矩阵。</p><p>3、拟牛顿算法把牛顿算法近似为<span class="math inline">\(\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}-\alpha_{k} \mathbf{H}_{k} \mathbf{g}^{(k)}\)</span></p><p>4、在每次迭代时，通过<span class="math inline">\(\mathbf{x}^{(k)}\)</span>、<span class="math inline">\(\mathbf{x}^{(k+1)}\)</span>、<span class="math inline">\(\mathbf{g}^{(k)}\)</span>、<span class="math inline">\(\mathbf{g}^{(k+1)}\)</span>、<span class="math inline">\(\mathbf{H}_{k}\)</span>来计算并更新得到<span class="math inline">\(\mathbf{H}^{(k+1)}\)</span>。</p><h2 id="拟牛顿法-1">拟牛顿法</h2><p>1、<span class="math inline">\(\mathbf{H}_{k}\)</span>是黑塞逆的近似。</p><p>2、<span class="math inline">\(\mathbf{H}_{k}\)</span>模仿了<span class="math inline">\(\mathbf{F}\left(\mathbf{x}^{(k)}\right)^{-1}\)</span>的三个特性。</p><blockquote><ul><li><span class="math inline">\(\mathbf{H}_{k}\)</span>是对称矩阵。</li><li><span class="math inline">\(\mathbf{H}_{k}\)</span>是正定的，保证下降特性。</li><li><span class="math inline">\(\mathbf{H}_{k}\)</span>具有“割线”特性。</li></ul></blockquote><p>3、这是<span class="math inline">\(\mathbf{H}_{k}\)</span>序列满足的条件，也是拟牛顿法的基础。</p><blockquote><p>拟牛顿法算法</p></blockquote><p><span class="math display">\[\begin{aligned} &amp;\mathbf{d}^{(k)}=-\mathbf{H}_{k} \mathbf{g}^{(k)}\\ &amp;\alpha_{k}=\arg \min _{\alpha \geq 0} f\left(\mathbf{x}^{(k)}+\alpha \mathbf{d}^{(k)}\right)=-\frac{\mathbf{g}^{(k) T} \mathbf{d}^{(k)}}{\mathbf{d}^{(k) T} Q \mathbf{d}^{(k)}}\\ &amp;\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}+\alpha_{k} \mathbf{d}^{(k)} \end{aligned}\]</span></p><p>其中<span class="math inline">\(\mathbf{H}_{0}, \mathbf{H}_{1}, \dots\)</span>是对称矩阵。</p><p>在二次型情况下，上述矩阵必须满足</p><p><span class="math display">\[\mathbf{H}_{k+1} \Delta \mathbf{g}^{(i)}=\Delta \mathbf{x}^{(i)}, \quad 0 \leq i \leq k\]</span></p><p>拟牛顿法是共轭方向法，因此如果将拟牛顿法应用到二次型中，并且黑塞矩阵<span class="math inline">\(\mathbf{Q}=\mathbf{Q}^{T}\)</span>，对于<span class="math inline">\(0 \leq k &lt; n-1\)</span>，就有</p><p><span class="math display">\[\mathbf{H}_{k+1} \Delta \mathbf{g}^{(i)}=\Delta \mathbf{x}^{(i)}, \quad 0 \leq i \leq k\]</span></p><p>其中<span class="math inline">\(\mathbf{H}_{k+1} = \mathbf{H}_{k+1}^{\top}\)</span>。如果<span class="math inline">\(\alpha_{i} \neq 0,0 \leq i \leq k\)</span>，那么<span class="math inline">\(\mathbf{d}^{(0)}, \ldots, \mathbf{d}^{(k+1)}\)</span>是<span class="math inline">\(\mathbf{Q}\)</span>共轭。</p><p>生成<span class="math inline">\(\mathbf{H}_{k}\)</span>有三个方法，分别是</p><blockquote><ul><li>1、秩1法</li><li>2、DFP法</li><li>3、BFGS法</li></ul></blockquote><p>并且这些方法都有下面的形式</p><p><span class="math display">\[\mathbf{H}_{k+1}=\mathbf{H}_{k}+\mathbf{U}_{k}\]</span></p><p>其中<span class="math inline">\(\mathbf{U}_{k}\)</span>使用<span class="math inline">\(\mathbf{H}_{k}\)</span>、<span class="math inline">\(\Delta \mathbf{g}^{(k)}\)</span>和<span class="math inline">\(\Delta \mathbf{x}^{(k)}\)</span>计算得到。</p><h2 id="秩1法">秩1法</h2><blockquote><p>公式</p></blockquote><p><span class="math display">\[\mathbf{U}_{k}=\alpha_{k} \mathbf{z}^{(k)} \mathbf{z}^{(k) T}\]</span></p><p>其中<span class="math inline">\(\alpha_{k} \in \mathbb{R}\)</span>，并且<span class="math inline">\(\mathbf{z}^{(k)} \in \mathbb{R}^{n}\)</span>。同时</p><p><span class="math display">\[\operatorname{rank} \mathbf{z}^{(k)} \mathbf{z}^{(k) T}=\operatorname{rank}\left(\left[\begin{array}{c} {z_{1}^{(k)}} \\ {\vdots} \\ {z_{n}^{(k)}} \end{array}\right]\left[\begin{array}{ccc} {z_{1}^{(k)}} &amp; {\cdots} &amp; {z_{n}^{(k)}} \end{array}\right]\right)=1\]</span></p><p>根据推导得到</p><p><span class="math display">\[\mathbf{U}_{k}=\frac{\left(\Delta \mathbf{x}^{(k)}-\mathbf{H}_{k} \Delta \mathbf{g}^{(k)}\right)\left(\Delta \mathbf{x}^{(k)}-\mathbf{H}_{k} \Delta \mathbf{g}^{(k)}\right)^{T}}{\left(\Delta \mathbf{x}^{(k)}-\mathbf{H}_{k} \Delta \mathbf{g}^{(k)}\right)^{T} \Delta \mathbf{g}^{(k)}}\]</span></p><p>所以</p><p><span class="math display">\[\alpha_{k}=\frac{1}{\left(\Delta \mathbf{x}^{(k)}-\mathbf{H}_{k} \Delta \mathbf{g}^{(k)}\right)^{T} \Delta \mathbf{g}^{(k)}}\]</span></p><p><span class="math display">\[\mathbf{z}^{(k)}=\Delta \mathbf{x}^{(k)}-\mathbf{H}_{k} \Delta \mathbf{g}^{(k)}\]</span></p><blockquote><p>总结整个流程</p></blockquote><p>1、首先把目标函数<span class="math inline">\(f\)</span>转化为二次型函数<span class="math inline">\(f(\mathbf{x})=\frac{1}{2} \mathbf{x}^{T} Q \mathbf{x}-\mathbf{b}^{T} \mathbf{x}\)</span>。</p><p>2、根据二次型函数获得函数<span class="math inline">\(f\)</span>在<span class="math inline">\(\mathbf{x}^{(k)}\)</span>的梯度<span class="math inline">\(\mathbf{g}^{(k)}\)</span>。</p><p>3、根据<span class="math inline">\(\mathbf{x}\)</span>的维度<span class="math inline">\(n\)</span>创建<span class="math inline">\(n\)</span>维度的单位矩阵<span class="math inline">\(\mathbf{H}_{0}\)</span>。</p><p>4、根据<span class="math inline">\(\mathbf{d}^{(k)}=-\mathbf{H}_{k} \mathbf{g}^{(k)}\)</span>计算方向向量<span class="math inline">\(\mathbf{d}^{(0)}\)</span>。</p><p>5、由于目标函数为二次型，因此根据步长公式<span class="math inline">\(\alpha_{k}=\arg \min _{\alpha \geq 0} f\left(\mathbf{x}^{(k)}+\alpha \mathbf{d}^{(k)}\right)=-\frac{\mathbf{g}^{(k) T} \mathbf{d}^{(k)}}{\mathbf{d}^{(k) T} Q \mathbf{d}^{(k)}}\)</span>得到步长<span class="math inline">\(\alpha_{0}\)</span>。</p><p>6、根据<span class="math inline">\(\mathbf{x}^{(k+1)}=\mathbf{x}^{(k)}+\alpha_{k} \mathbf{d}^{(k)}\)</span>计算得到<span class="math inline">\(\mathbf{x}^{(1)}\)</span>。</p><p>7、根据上式计算得到<span class="math inline">\(\Delta \mathbf{x}^{(0)}\)</span>，<span class="math inline">\(\Delta \mathbf{x}^{(k)}=\alpha_{k} \mathbf{d}^{(k)}\)</span>。</p><p>8、根据二次型公式计算梯度得到<span class="math inline">\(\mathbf{g}^{(1)}\)</span>，<span class="math inline">\(\mathbf{g}^{(k)}=Q \mathbf{x}^{(k)}\)</span>.</p><p>9、根据<span class="math inline">\(\mathbf{g}^{(1)}\)</span>得到<span class="math inline">\(\Delta \mathbf{g}^{(0)}\)</span>，<span class="math inline">\(\mathbf{g}^{(k+1)}-\mathbf{g}^{(k)}\)</span>。</p><p>10、根据秩1法得到<span class="math inline">\(\alpha_{k}\)</span>，<span class="math inline">\(\Delta \mathbf{g}^{(0) T}\left(\Delta \mathbf{x}^{(0)}-\mathbf{H}_{0} \Delta \mathbf{g}^{(0)}\right)\)</span>。</p><p>11、计算得到<span class="math inline">\(\mathbf{U}_{k}\)</span>。</p><p>12、得到<span class="math inline">\(\mathbf{d}^{(1)}\)</span>的方向向量。</p><p>13、从第五步开始迭代执行<span class="math inline">\(n\)</span>次得到<span class="math inline">\(\mathbf{x}^{*}\)</span>。</p><blockquote><p>不足</p></blockquote><p>1、<span class="math inline">\(\mathbf{H}_{k}\)</span>不一定是正定，这将导致<span class="math inline">\(\mathbf{d}^{(k)}=-\mathbf{H}_{k} \mathbf{g}^{(k)}\)</span>不一定是下降方向。</p><p>2、当<span class="math inline">\(\Delta \mathbf{g}^{(k) T}\left(\Delta \mathbf{x}^{(k)}-\mathbf{H}_{k} \Delta \mathbf{g}^{(k)}\right) \approx 0\)</span>时，<span class="math inline">\(\mathbf{H}_{k+1}\)</span>的计算有困难。</p><h2 id="dfp算法变尺度算法">DFP算法（变尺度算法）</h2><blockquote><p>公式</p></blockquote><p><span class="math display">\[\mathbf{U}_{k}=\frac{\Delta \mathbf{x}^{(k)} \Delta \mathbf{x}^{(k) T}}{\Delta \mathbf{x}^{(k) T} \Delta \mathbf{g}^{(k)}}-\frac{\mathbf{H}_{k} \Delta \mathbf{g}^{(k)} \Delta \mathbf{g}^{(k) T} \mathbf{H}_{k}}{\Delta \mathbf{g}^{(k) T} \mathbf{H}_{k} \Delta \mathbf{g}^{(k)}}\]</span></p><p>所以</p><p><span class="math display">\[\mathbf{H}_{k+1}=\mathbf{H}_{k}+\frac{\Delta \mathbf{x}^{(k)} \Delta \mathbf{x}^{(k) T}}{\Delta \mathbf{x}^{(k) T} \Delta \mathbf{g}^{(k)}}-\frac{\mathbf{H}_{k} \Delta \mathbf{g}^{(k)} \Delta \mathbf{g}^{(k) T} \mathbf{H}_{k}}{\Delta \mathbf{g}^{(k) T} \mathbf{H}_{k} \Delta \mathbf{g}^{(k)}}\]</span></p><blockquote><p>特性</p></blockquote><p>1、DFP算法是拟牛顿算法（满足拟牛顿条件）。</p><p>2、当DFP算法用于二次型时，并且黑塞举证<span class="math inline">\(\mathbf{Q}=\mathbf{Q}^{T}\)</span>，那么就有</p><p><span class="math display">\[\mathbf{H}_{k+1} \Delta \mathbf{g}^{(i)}=\Delta \mathbf{x}^{(i)}, \quad 0 \leq i \leq k\]</span></p><p>3、DFP算法也是一个共轭方向算法。</p><p>4、定理：如果<span class="math inline">\(\mathbf{g}^{(k)} \neq 0\)</span>，那么在DFP中，<span class="math inline">\(\mathbf{H}_{k}\)</span>一定是正定矩阵。</p><p>5、DFP使得<span class="math inline">\(\mathbf{H}_{k}\)</span>具有正定性。</p><p>6、DFP优于秩1算法。</p><p>7、DFP算法在某些情况下可能会有问题（例如：非常大的非二次问题）。</p><h2 id="bfgs算法">BFGS算法</h2><blockquote><p>公式</p></blockquote><p><span class="math display">\[\mathbf{U}_{k}=\left(1+\frac{\Delta \mathbf{g}^{(k) T} \mathbf{H}_{k} \Delta \mathbf{g}^{(k) T}}{\Delta \mathbf{g}^{(k) T} \Delta \mathbf{x}^{(k)}}\right) \frac{\Delta \mathbf{x}^{(k)} \Delta \mathbf{x}^{(k) T}}{\Delta \mathbf{x}^{(k) T} \Delta \mathbf{g}^{(k)}}-\frac{\mathbf{H}_{k} \Delta \mathbf{g}^{(k)} \Delta \mathbf{x}^{(k) T}+\left(\mathbf{H}_{k} \Delta \mathbf{g}^{(k)} \Delta \mathbf{x}^{(k) T}\right)^{T}}{\Delta \mathbf{g}^{(k) T} \Delta \mathbf{x}^{(k)}}\]</span></p><p><span class="math display">\[\mathbf{H}_{k+1}=\mathbf{H}_{k}+\mathbf{U}_{k}\]</span></p><blockquote><p>特性</p></blockquote><p>1、BFGS使用互补性，从DFP中导出。</p><p>2、考虑拟牛顿条件，Hessian逆的近似应满足</p><p><span class="math display">\[\mathbf{H}_{k+1} \Delta \mathbf{g}^{(i)}=\Delta \mathbf{x}^{(i)}, \quad 0 \leq i \leq k\]</span></p><p>3、令<span class="math inline">\(\mathbf{B}_{k}\)</span>是一个黑塞矩阵的近似（<span class="math inline">\(\mathbf{B}_{k}^{-1}=\mathbf{H}_{k}\)</span>）,那么就可以得到</p><p><span class="math display">\[\mathbf{B}_{k+1} \Delta \mathbf{x}^{(i)}=\Delta \mathbf{g}^{(i)}, \quad 0 \leq i \leq k\]</span></p><p>将上述条件称为“互补拟牛顿”条件。</p><p>之前的公式对于更新<span class="math inline">\(\mathbf{B}_{k+1}\)</span>不是很有用，因为我们需要的是逆黑塞</p><p><span class="math display">\[\mathbf{H}_{k+1}^{B F G S}=\left(\mathbf{B}_{k+1}\right)^{-1}\]</span></p><p>存在一些计算逆的技巧，如下面的Sherman Morrison公式所示</p><p>引理：如果矩阵<span class="math inline">\(\mathbf{A}\)</span>不是奇异矩阵，<span class="math inline">\(\mathbf{u}\)</span>和<span class="math inline">\(\mathbf{v}\)</span>是列向量，满足<span class="math inline">\(1+\mathbf{v}^{T} \mathbf{A}^{-1} \mathbf{u} \neq 0\)</span>，那么<span class="math inline">\(\mathbf{A}+\mathbf{u} \mathbf{v}^{T}\)</span>非奇异，其逆矩阵可以用<span class="math inline">\(\mathbf{A}^{-1}\)</span>来表示</p><p><span class="math display">\[\left(\mathbf{A}+\mathbf{u v}^{T}\right)^{-1}=\mathbf{A}^{-1}-\frac{\left(\mathbf{A}^{-1} \mathbf{u}\right)\left(\mathbf{v}^{T} \mathbf{A}^{-1}\right)}{1+\mathbf{v}^{T} \mathbf{A}^{-1} \mathbf{u}}\]</span></p><p>因此可以知道如果<span class="math inline">\(\mathbf{A}^{-1}\)</span>已知，</p><p>如果<span class="math inline">\(\mathbf{A}^{-1}\)</span>是已知的，那么这个公式提供了一种“数值廉价”的方法来计算由矩阵<span class="math inline">\(\mathbf{A}\)</span>校正的<span class="math inline">\(\mathbf{u} \mathbf{v}^{T}\)</span>的逆。</p><p>此时，上面的公式就变为</p><p><span class="math display">\[\mathbf{B}_{k+1}=\mathbf{B}_{k}+\mathbf{u}_{1} \mathbf{v}_{1}^{T}+\mathbf{u}_{2} \mathbf{v}_{2}^{T}\]</span></p><p>因此</p><p><span class="math display">\[\mathbf{B}_{k+1}^{-1}=\left(\mathbf{B}_{k}+\mathbf{u}_{1} \mathbf{v}_{1}^{T}+\mathbf{u}_{2} \mathbf{v}_{2}^{T}\right)^{-1}\]</span></p><p>将引理应用于$<em>{k+1}<span class="math inline">\(2次，并使用\)</span></em>{k}<span class="math inline">\(替换\)</span>_{k}^{-1}$，就可以得到</p><p><span class="math display">\[\mathbf{H}_{k+1}^{B F G S}=\mathbf{H}_{k}+\left(1+\frac{\Delta \mathbf{g}^{(k) T} \mathbf{H}_{k} \Delta \mathbf{g}^{(k) T}}{\Delta \mathbf{g}^{(k) T} \Delta \mathbf{x}^{(k)}}\right) \frac{\Delta \mathbf{x}^{(k)} \Delta \mathbf{x}^{(k) T}}{\Delta \mathbf{x}^{(k) T} \Delta \mathbf{g}^{(k)}}- \frac{\mathbf{H}_{k} \Delta \mathbf{g}^{(k)} \Delta \mathbf{x}^{(k) T}+\left(\mathbf{H}_{k} \Delta \mathbf{g}^{(k)} \Delta \mathbf{x}^{(k) T}\right)^{T}}{\Delta \mathbf{g}^{(k) T} \Delta \mathbf{x}^{(k)}}\]</span></p><p>从而更新了<span class="math inline">\(\mathbf{H}_{k}\)</span>。</p><p>1、BFGS是DFP的“补充”公式</p><p>2、由于互补性，BFGS公式继承了DFP的性质</p><blockquote><ul><li>满足拟牛顿条件。</li><li>BFGS具有共轭方向性质。</li><li>BFGS继承了DFP的正定性，即当<span class="math inline">\(\mathbf{g}^{(k)} \neq 0\)</span>，并且<span class="math inline">\(\mathbf{H}_{k}&gt;0\)</span>，那么<span class="math inline">\(\mathbf{H}_{k+1}^{B F G S}&gt;0\)</span>。</li></ul></blockquote><p>3、当直线搜索准确时，BFGS具有相当强的鲁棒性（可以节省直线搜索部分的时间）。</p><p>4、BFGS通常比DFP公式有效得多。</p><p>5、对于非二次问题，拟牛顿算法通常不会在<span class="math inline">\(n\)</span>步内收敛。</p><p>6、需要进行一些修改（例如，在每次迭代后将方向向量重新初始化为负梯度）。</p><p>7、广泛应用。</p><h1 id="线性规划">线性规划</h1><h2 id="标准型线性规划">标准型线性规划</h2> <span class="math display">\[\begin{matrix} minimize &amp; \mathbf{c}^{T} \mathbf{x}\\ st. &amp; \mathbf{A x}=\mathbf{b}\\ &amp; \mathbf{x} \geq 0 \end{matrix}\]</span><p>其中<span class="math inline">\(\mathbf{A}\)</span>是<span class="math inline">\(m \times n\)</span>，<span class="math inline">\(m &lt; n\)</span>，<span class="math inline">\(\operatorname{rank}(\mathbf{A})=m\)</span>，并且<span class="math inline">\(\mathbf{b} \geq 0\)</span>。</p><p>如果把LP问题转化为标准型？</p><p>1、如果问题是最大化，则简单地将目标函数乘以-1以最小化。</p><p>2、如果<span class="math inline">\(\mathbf{A}\)</span>不是满秩，那么就移除一行或多行。</p><p>3、如果<span class="math inline">\(\mathbf{b}\)</span>的一个分量是负的，比如第<span class="math inline">\(i\)</span>个分量，将第<span class="math inline">\(i\)</span>个约束乘以-1，右边就得到正的。</p><h2 id="不等式约束的情况">不等式约束的情况</h2><h3 id="转化为标准型松弛变量">转化为标准型：松弛变量</h3><p>假设有一个不等式约束</p><p><span class="math display">\[a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n} x_{n} \leq b\]</span></p><p>通过引入松弛变量，可以将上述不等式约束转化为标准等式约束。</p><p>具体来说，上述约束相当于</p><p><span class="math display">\[\begin{matrix} a_{1} x_{1}+a_{2} x_{2}+\dots+a_{n} x_{n}+x_{n+1}=b \\ x_{n+1} \geq 0 \end{matrix}\]</span></p><p>其中松弛变量为<span class="math inline">\(x_{n+1}\)</span>。</p><h3 id="转化为标准型剩余变量">转化为标准型：剩余变量</h3><p>假设有一个不等式约束</p><p><span class="math display">\[a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n} x_{n} \geq b\]</span></p><p>可以通过引入一个剩余变量将上述不等式约束转化为标准等式约束</p><p>具体来说，上述约束相当于</p><p><span class="math display">\[\begin{matrix} a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n} x_{n}-x_{n+1}=b \\ x_{n+1} \geq 0 \end{matrix}\]</span></p><h3 id="转化为标准型非正变量">转化为标准型：非正变量</h3><p>假设变量中的一个（比如<span class="math inline">\(x_{1}\)</span>）有下面的约束</p><p><span class="math display">\[x_{1} \leq 0\]</span></p><p>可以通过将<span class="math inline">\(x_{1}\)</span>的每一次出现都改为它的负数，从而把这个变量转换成通常的非负变量<span class="math inline">\(x_{1}^{\prime}=-x_{1}\)</span></p><p>假如有约束</p><p><span class="math display">\[\begin{matrix} a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n} x_{n}=b \\ x_{1} \leq 0 \end{matrix}\]</span></p><p>通过引入<span class="math inline">\(x_{1}^{\prime}=-x_{1}\)</span>得到下面的约束</p><p><span class="math display">\[\begin{matrix} -a_{1} x_{1}^{\prime}+a_{2} x_{2}+\cdots+a_{n} x_{n}=b \\ x_{1}^{\prime} \geq 0 \end{matrix}\]</span></p><h3 id="转化为标准型自由变量">转化为标准型：自由变量</h3><p>假设变量中的一个（比如<span class="math inline">\(x_{1}\)</span>）没有非负性约束（例如不存在<span class="math inline">\(x_{1} \geq 0\)</span>约束）</p><p>通过引入变量<span class="math inline">\(u_{1} \geq 0\)</span>和<span class="math inline">\(v_{1} \geq 0\)</span>，并且使用<span class="math inline">\(u_{1}-v_{1}\)</span>来替代<span class="math inline">\(\mathcal{X}_{1}\)</span></p><p>例如有约束</p><p><span class="math display">\[a_{1} x_{1}+a_{2} x_{2}+\cdots+a_{n} x_{n}=b\]</span></p><p>那么就可以等价为</p><p><span class="math display">\[\begin{matrix} a_{1}\left(u_{1}-v_{1}\right)+a_{2} x_{2}+\cdots+a_{n} x_{n}=b \\ u_{1}, v_{1} \geq 0 \end{matrix}\]</span></p><h2 id="基本解决方案">基本解决方案</h2> <span class="math display">\[\begin{matrix} minimize &amp; \mathbf{c}^{T} \mathbf{x}\\ st. &amp; \mathbf{A x}=\mathbf{b}\\ &amp; \mathbf{x} \geq 0 \end{matrix}\]</span><p>其中<span class="math inline">\(\mathbf{A}\)</span>是<span class="math inline">\(m \times n\)</span>，<span class="math inline">\(m &lt; n\)</span>，<span class="math inline">\(\operatorname{rank}(\mathbf{A})=m\)</span>，并且<span class="math inline">\(\mathbf{b} \geq 0\)</span>。</p><p>线性方程组有解的条件</p><p>1、如果<span class="math inline">\(\operatorname{rank}[\mathbf{A}]=\operatorname{rank}[\mathbf{A}, \mathbf{b}]\)</span>，那么线性方程有解。</p><p>2、<span class="math inline">\(\operatorname{rank}[\mathbf{A}]=n\)</span>，那么线性方程的解不唯一。</p><p>3、<span class="math inline">\(\operatorname{rank}[\mathbf{A}] &lt; n\)</span>，那么线性方程有无穷解。</p><p>当<span class="math inline">\(m &lt; n\)</span>，有无穷多个点满足<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>。</p><p>如果有矩阵<span class="math inline">\(\mathbf{A}\)</span>，以及矩阵<span class="math inline">\(\mathbf{A}\)</span>中的一组<span class="math inline">\(m\)</span>个线性无关列向量，那么<span class="math inline">\(\mathbf{A}=[\mathbf{B}, \mathbf{D}]\)</span>，其中<span class="math inline">\(\mathbf{D}\)</span>是<span class="math inline">\(m \times(n-m)\)</span>维矩阵。</p><p>那么就可以求解方程<span class="math inline">\(\mathbf{B} \mathbf{x}_{B}=\mathbf{b}\)</span>，并且方程的解为<span class="math inline">\(\mathbf{x}_{B}=\mathbf{B}^{-1} \mathbf{b}\)</span>。</p><p>让<span class="math inline">\(\mathbf{x}=\left[\mathbf{x}_{B}^{T}, \mathbf{0}^{T}\right]^{T}\)</span>，那么<span class="math inline">\(\mathbf{x}\)</span>就是方程<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>的解。</p><p>1、如果<span class="math inline">\(\mathbf{x}\)</span>满足<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>，那么<span class="math inline">\(\mathbf{x}\)</span>就是基本解。</p><p>2、如果<span class="math inline">\(\mathbf{x}\)</span>满足<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>，且<span class="math inline">\(\mathbf{x} \geq 0\)</span>，那么<span class="math inline">\(\mathbf{x} \geq 0\)</span>是可行解，可行解也是基本可行解。</p><p>3、如果<span class="math inline">\(\mathbf{x}\)</span>中有一些为0，那么基本可行解就是退化的基本解。</p><p>4、如果<span class="math inline">\(\mathbf{x}\)</span>满足基本可行解，但其中有一些为0，那么就是退化的基本可行解。</p><h2 id="基本解的性质">基本解的性质</h2><blockquote><p>定义</p></blockquote><p>对于任何满足约束条件<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>，<span class="math inline">\(\mathbf{x} \geq 0\)</span>的向量<span class="math inline">\(\mathbf{x}\)</span>，如果它能够使目标函数<span class="math inline">\(\mathbf{c}^{T} \mathbf{x}\)</span>取得极小值，那么就将其称为最有可行解。如果最有可行解是基本解，那么它就是最有基本可行解。</p><blockquote><p>定理</p></blockquote><p>1、如果存在可行解，那么一定存在基本可行解。</p><p>2、如果存在最优可行解，那么一定存在最优基本可行解。</p><p>有个定理后</p><p>1、线性规划的基本定理将求解线性规划问题的任务简化为搜索基本可行解的任务。</p><p>2、只需要检查最优性的基本可行解。</p><p>3、基本解的数量最大可以是</p><p><span class="math display">\[\left(\begin{array}{c} {n} \\ {m} \end{array}\right)=\frac{n !}{m !(n-m) !}\]</span></p><p>其中<span class="math inline">\(m\)</span>是秩，<span class="math inline">\(n\)</span>是维度。</p><p>4、注意，虽然这个数字是有限的，但它可能非常大。</p><h2 id="几何视角下的线性规划">几何视角下的线性规划</h2><blockquote><p>定理：如果可行集<span class="math inline">\(\mathbf{A x}=\mathbf{b}, \quad \mathbf{x} \geq 0\)</span>存在，那么它一定是凸集。</p></blockquote><p>1、约束集的极值点等价于基本可行解（BFS）</p><p>2、几何上，BFS对应于约束集的“角”点（顶点）。</p><p>3、如果可行集是非空的，那么它有一个顶点。</p><p>4、如果问题有一个极小值（最优），那么其中一个顶点就是一个极小值。</p><p>可以得到</p><p>1、极值点集等于基本可行解集。</p><p>2、结合LP的基本定理，可以看出求解LP问题只需要考察约束集的极值点。</p><h1 id="整数规划问题">整数规划问题</h1><p>整数规划的一般形式</p> <span class="math display">\[\begin{matrix} minimize &amp; f(\mathbf{x})\\ st. &amp; \mathbf{g}(\mathbf{x}) \leq 0\\ &amp; \mathbf{x} \in \mathbb{Z}^{n} \end{matrix}\]</span><p>整数规划问题是一个NP难问题。</p><h2 id="整数线性规划">整数线性规划</h2> <span class="math display">\[\begin{matrix} minimize &amp; \mathbf{c}^{\top} \mathbf{x}\\ st. &amp; \mathbf{Ax}=\mathbf{b}\\ &amp; \mathbf{x} \geq \mathbf{0}\\ &amp; \mathbf{x} \in \mathbb{Z}^{n}\\ \end{matrix}\]</span><h2 id="解决ilp的方法">解决ILP的方法</h2><p>1、把ILP变为LP问题</p><p>2、特殊情况：幺模矩阵</p><p>3、精确方法</p><blockquote><ul><li>1、割平面法</li><li>2、动态规划法</li><li>3、分支边界法</li><li>4、分支切割法</li></ul></blockquote><p>4、启发式方法</p><h2 id="幺模矩阵">幺模矩阵</h2><blockquote><p>定义：对于<span class="math inline">\(m \times n\)</span>的整型矩阵<span class="math inline">\(\mathbf{A} \in \mathbb{Z}^{m \times n}(m 《 n)\)</span>，如果其所有<span class="math inline">\(m\)</span>阶非零子式为<span class="math inline">\(\pm 1\)</span>，那么矩阵<span class="math inline">\(\mathbf{A}\)</span>就是幺模矩阵。</p></blockquote><p>假设线性方程<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>，其中<span class="math inline">\(\mathbf{A} \in \mathbb{Z}^{m \times n}(m \leq n)\)</span>，<span class="math inline">\(\mathbf{B}\)</span>是一个基矩阵（由<span class="math inline">\(m\)</span>个线性无关的列向量组成<span class="math inline">\(m \times m\)</span>矩阵），<span class="math inline">\(\mathbf{A}\)</span>的幺模矩阵是<span class="math inline">\(|\operatorname{det} \mathbf{B}|=1\)</span>的所有<span class="math inline">\(\mathbf{B}\)</span>。</p><blockquote><p>引理：对于线性方程<span class="math inline">\(\mathbf{A x}=\mathbf{b}\)</span>，其中<span class="math inline">\(\mathbf{A} \in \mathbb{Z}^{m \times n}(m \leq n)\)</span>是幺模矩阵，并且<span class="math inline">\(\mathbf{b} \in \mathbb{Z}^{m}\)</span>，那么它的所有基本解都是整数解。</p></blockquote><blockquote><p>推论：如果线性规划的约束方程<span class="math inline">\(\mathbf{A x}=\mathbf{b}, \mathbf{x} \geq 0\)</span>，其中<span class="math inline">\(\mathbf{A}\)</span>是幺模矩阵，<span class="math inline">\(\mathbf{A} \in \mathbb{Z}^{m \times n}\)</span>，并且<span class="math inline">\(\mathbf{b} \in \mathbb{Z}^{m}\)</span>，那么所有的基本可行解都是整数。</p></blockquote><blockquote><p>定义：对于一个<span class="math inline">\(m \times n\)</span>的整数矩阵<span class="math inline">\(\mathbf{A} \in \mathbb{Z}^{m \times n}\)</span>，如果它的所有非零子式都是<span class="math inline">\(\pm 1\)</span>，那么矩阵<span class="math inline">\(\mathbf{A}\)</span>就是幺模矩阵。</p></blockquote><blockquote><p>推论：考虑线性规划的约束条件<span class="math inline">\([\mathbf{A}, \mathbf{I}] \mathbf{x}=\mathbf{b}, \mathbf{x} \geq 0\)</span>，其中<span class="math inline">\(\mathbf{A} \in \mathbb{Z}^{m \times n}\)</span>是完全幺模矩阵，<span class="math inline">\(\mathbf{b} \in \mathbb{Z}^{m}\)</span>，那么他的所有基本可行解都是整数解。</p></blockquote><h2 id="割平面法">割平面法</h2><h3 id="主要思想">主要思想</h3><p>1、通过LP松弛来解决ILP问题。</p><p>2、验证解</p><blockquote><ul><li>如果最优化解是整型，那么就得到解。</li><li>如果不是，那么就需要增加约束来移除在可行集中的非整数最优解。</li></ul></blockquote><p>3、重复该过程，直到最优解为整数向量。</p><h3 id="流程">流程</h3><p>1、引入向下取整操作，表示为<span class="math inline">\(\lfloor x\rfloor\)</span>。</p><p>2、定义整数线性规划问题</p> <span class="math display">\[\begin{matrix} minimize &amp; \mathbf{c}^{\top} \mathbf{x}\\ st. &amp; \mathbf{Ax}=\mathbf{b}\\ &amp; \mathbf{x} \geq \mathbf{0}\\ &amp; \mathbf{x} \in \mathbb{Z}^{n}\\ \end{matrix}\]</span><p>3、我们首先得到线性规划问题的最优基本可行解。</p> <span class="math display">\[\begin{matrix} minimize &amp; \mathbf{c}^{T} \mathbf{x}\\ st. &amp; \mathbf{A x}=\mathbf{b}\\ &amp; \mathbf{x} \geq 0 \end{matrix}\]</span><p>4、假设前<span class="math inline">\(m\)</span>列向量组成了最有基本可行解的基矩阵，则相应的增广矩阵为</p><p><span class="math display">\[\begin{array}{cccccccccc} {a_{1}} &amp; {a_{2}} &amp; {\cdots} &amp; {a_{i}} &amp; {\cdots} &amp; {a_{m}} &amp; {a_{m+1}} &amp; {\cdots} &amp; {a_{n}} &amp; {y_{0}} \\ {1} &amp; {0} &amp; {\cdots} &amp; {0} &amp; {\cdots} &amp; {0} &amp; {y_{1, m+1}} &amp; {\cdots} &amp; {y_{1, n}} &amp; {y_{10}} \\ {0} &amp; {1} &amp; {\cdots} &amp; {0} &amp; {\cdots} &amp; {0} &amp; {y_{2, m+1}} &amp; {\cdots} &amp; {y_{2, n}} &amp; {y_{20}} \\ {\vdots} &amp; {\vdots} &amp; {} &amp; {\vdots} &amp; {} &amp; {\vdots} &amp; {} &amp; {} &amp; {} &amp; {\vdots} \\ {0} &amp; {0} &amp; {\cdots} &amp; {1} &amp; {\cdots} &amp; {0} &amp; {y_{i, m+1}} &amp; {\cdots} &amp; {y_{i, n}} &amp; {y_{i 0}} \\ {\vdots} &amp; {\vdots} &amp; {} &amp; {\vdots} &amp; {} &amp; {\vdots} &amp; {} &amp; {} &amp; {\vdots} &amp; {\vdots} \\ {0} &amp; {0} &amp; {\cdots} &amp; {0} &amp; {\cdots} &amp; {1} &amp; {y_{m, m+1}} &amp; {\cdots} &amp; {y_{m, n}} &amp; {y_{m 0}} \end{array}\]</span></p><p>5、假设最有基本可行解中的第<span class="math inline">\(i\)</span>个元素<span class="math inline">\(y_{i 0}\)</span>不是整数。注意，任何可行向量<span class="math inline">\(\mathbf{X}\)</span>都满足等式约束</p><p><span class="math display">\[x_{i}+\sum_{j=m+1}^{n} y_{i j} x_{j}=y_{i 0}\]</span></p><p>6、利用上式就可以构造出新增的约束条件。</p><blockquote><ul><li>从可行集中消除当前最优非整数解。</li><li>保持任何整数可行解。</li></ul></blockquote><p><span class="math display">\[x_{i}+\sum_{j=m+1}^{n}\left\lfloor y_{i j}\right\rfloor x_{j} \leq y_{i 0}\]</span></p><blockquote><ul><li>因为<span class="math inline">\(\left\lfloor y_{i j}\right\rfloor \leq y_{i j}\)</span>，所以对于任何满足上面等式约束的向量<span class="math inline">\(\mathbf{x} \geq 0\)</span>，也满足这一不等式约束。</li><li>任何可行解<span class="math inline">\(\mathbf{X}\)</span>都满足该不等式约束。</li></ul></blockquote><p>此外，对于任何整数可行向量<span class="math inline">\(\mathbf{x}\)</span>，不等式约束的左边都是整数，因此，任意整数可行解<span class="math inline">\(\mathbf{x}\)</span>还满足</p><p><span class="math display">\[x_{i}+\sum_{j=m+1}^{n}\left\lfloor y_{i j}\right\rfloor x_{j} \leq\left\lfloor y_{i 0}\right\rfloor\]</span></p><blockquote><ul><li>将前面的等式约束减去不等式约束，可以得到任意整数可行解<span class="math inline">\(\mathbf{x}\)</span>都满足的约束条件。</li></ul></blockquote><p><span class="math display">\[\sum_{j=m+1}^{n}\left(y_{i j}-\left\lfloor y_{i j}\right\rfloor\right) x_{j} \geq y_{i 0}-\left\lfloor y_{i 0}\right\rfloor\]</span></p><blockquote><ul><li>通过引入一个剩余变量<span class="math inline">\(x_{n+1}\)</span>可以把上面新的LP变为标准形式。</li></ul></blockquote><p><span class="math display">\[\sum_{j=m+1}^{n}\left(y_{i j}-\left\lfloor y_{i j}\right\rfloor\right) x_{j}-x_{n+1}=y_{i 0}-\left\lfloor y_{i 0}\right\rfloor\]</span></p><p>7、现在可以用单纯形法求解新的线性规划，并检查得到的最优基本可行解。</p><blockquote><ul><li>如果是整型，那么计算结束。</li><li>如果不是，那么就引入其他割面，并重复上面的过程。</li></ul></blockquote><p>注意，求解过程中引入的松弛变量，并不必须为整数。</p><h1 id="仅含等式约束的优化问题重新看">仅含等式约束的优化问题（重新看）</h1><p><span class="math display">\[\begin{matrix} minimize &amp; f\left ( \mathbf{x} \right ) &amp; \\ st. &amp; \mathbf{h}_{i}(\mathbf{x})=\mathbf{0} &amp; i=1, \ldots, m \end{matrix}\]</span></p><p>其中<span class="math inline">\(\mathbf{h}=\left[h_{1}, \dots, h_{m}\right]^{T}\)</span>，并且<span class="math inline">\(\mathbf{h}: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}, m &lt; n\)</span>。如果函数<span class="math inline">\(\mathbf{h}\)</span>是连续可微的，那么<span class="math inline">\(\mathbf{h} \in \mathcal{C}^{1}\)</span>。</p><p>定义（<span class="math inline">\(m=1\)</span>的情况）：当<span class="math inline">\(\nabla h\left(\mathbf{x}^{*}\right) \neq 0\)</span>时，那么可行点<span class="math inline">\(\mathbf{x}^{*}\)</span>为该约束的正则点。</p><p>如果<span class="math inline">\(S\)</span>上的所有点都是正则点，那么曲面<span class="math inline">\(S\)</span>的维数是<span class="math inline">\(n-m\)</span>。</p><h2 id="拉格朗日条件">拉格朗日条件</h2><p>首先定义<span class="math inline">\(m=1\)</span>的简单情况</p><p><span class="math display">\[\begin{matrix} minimize &amp; f\left ( \mathbf{x} \right ) &amp; \\ st. &amp; \mathbf{h}\left ( \mathbf{x} \right )=0 \end{matrix}\]</span></p><p>其中<span class="math inline">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>，<span class="math inline">\(h: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span></p><p>（<span class="math inline">\(m=1\)</span>的情况）假设<span class="math inline">\(\mathbf{x}^{*}\)</span>局部最小值，并且是正则点。那么存在一个标量<span class="math inline">\(\lambda^{*}\)</span>，使得</p><p><span class="math display">\[\nabla f\left(\mathbf{x}^{*}\right)+\lambda^{*} \nabla h\left(\mathbf{x}^{*}\right)=0\]</span></p><p>换句话说，<span class="math inline">\(\nabla f\left(\mathbf{x}^{*}\right)\)</span>和<span class="math inline">\(\nabla h\left(\mathbf{x}^{*}\right)\)</span>是平行的，<span class="math inline">\(\lambda^{*}\)</span>称为拉格朗日乘子。</p><h1 id="含不等式约束的优化问题">含不等式约束的优化问题</h1><p>1、<span class="math inline">\(\mu^{*} \geq 0\)</span></p><p>2、<span class="math inline">\(D f\left(\mathbf{x}^{*}\right)+\mu^{* T} D \mathbf{g}\left(\mathbf{x}^{*}\right)=\mathbf{0}^{T}\)</span></p><p>3、<span class="math inline">\(\mu^{* T} \mathbf{g}\left(\mathbf{x}^{*}\right)=0\)</span></p><p>4、<span class="math inline">\(\mathbf{g}\left(\mathbf{x}^{*}\right) \leq 0\)</span></p><h1 id="凸优化问题-1">凸优化问题</h1><p>如果<span class="math inline">\(\Omega\)</span>是凸集，那么任意<span class="math inline">\(\mathbf{y}, \mathbf{z} \in \Omega\)</span>，并且<span class="math inline">\(\alpha \in(0,1)\)</span>，都有<span class="math inline">\(\alpha \mathbf{y}+(1-\alpha) \mathbf{z} \in \Omega\)</span>。</p><h2 id="证明omegamathbfx-mathbfx-geq-0是凸集">证明<span class="math inline">\(\Omega=\{\mathbf{x}: \mathbf{x} \geq 0\}\)</span>是凸集</h2><p>1、假设<span class="math inline">\(\mathbf{y}, \mathbf{z} \in \Omega\)</span>，并且<span class="math inline">\(\alpha \in(0,1)\)</span>。</p><p>2、那么<span class="math inline">\(\mathbf{x}=\alpha \mathbf{y}+(1-\alpha) \mathbf{z} \in \Omega\)</span>。</p><p>3、若要要属于<span class="math inline">\(\Omega\)</span>，那么<span class="math inline">\(\mathbf{x}\)</span>中每个都必须<span class="math inline">\(\geq 0\)</span>。</p><p>4、每个<span class="math inline">\(\mathbf{x}=\left[x_{1}, \ldots, x_{n}\right]^{T}\)</span>满足<span class="math inline">\(x_{i}=\alpha y_{i}+(1-\alpha) z_{i}\)</span>。</p><p>5、就可以知道<span class="math inline">\(y_{i}, z_{i}, \alpha, 1-\alpha \geq 0\)</span>。</p><p>6、因此，<span class="math inline">\(x_{i} \geq 0\)</span>，所以<span class="math inline">\(\mathbf{x} \geq 0\)</span>，即<span class="math inline">\(\mathbf{x} \in \Omega\)</span>，所以<span class="math inline">\(\Omega\)</span>是凸集。</p><h2 id="凸方程">凸方程</h2><blockquote><p>定理：如果一个方程<span class="math inline">\(f\)</span>在<span class="math inline">\(\Omega\)</span>上是凸函数，那么任何不同的<span class="math inline">\(\mathbf{x}, \mathbf{y} \in \Omega\)</span>，并且<span class="math inline">\(\alpha \in(0,1)\)</span>，都有</p></blockquote><p><span class="math display">\[f(\alpha \mathbf{x}+(1-\alpha) \mathbf{y}) \leq \alpha f(\mathbf{x})+(1-\alpha) f(\mathbf{y})\]</span></p><p>如果<span class="math inline">\(f\)</span>是严格凸函数，那么<span class="math inline">\(\leq\)</span>会替换为<span class="math inline">\(&lt;\)</span>。</p><h2 id="验证二次型的凸函数">验证二次型的凸函数</h2><blockquote><p>命题：假设有二次型函数<span class="math inline">\(f(\mathbf{x})=\mathbf{x}^{T} \mathbf{Q} \mathbf{x}\)</span>，并且<span class="math inline">\(\mathbf{Q}=\mathbf{Q}^{T}\)</span>。假如<span class="math inline">\(\Omega\)</span>为凸集，那么<span class="math inline">\(f\)</span>是在<span class="math inline">\(\Omega\)</span>上是凸集的条件是</p></blockquote><p><span class="math display">\[(\mathbf{x}-\mathbf{y})^{T} \mathbf{Q}(\mathbf{x}-\mathbf{y}) \geq 0\]</span></p><p>并且所有的<span class="math inline">\(\mathbf{x}, \mathbf{y} \in \Omega\)</span>。</p><h2 id="凸函数的另一个解释">凸函数的另一个解释</h2><blockquote><p>定理：函数<span class="math inline">\(f\)</span>是凸函数的条件是所有<span class="math inline">\(\mathbf{x}, \mathbf{y} \in \Omega\)</span>，并且</p></blockquote><p><span class="math display">\[f(\mathbf{y}) \geq f(\mathbf{x})+D f(\mathbf{x})(\mathbf{y}-\mathbf{x})\]</span></p><blockquote><p>定理：如果函数<span class="math inline">\(f\)</span>是凸函数，那么黑塞矩阵<span class="math inline">\(\mathbf{F}(\mathbf{x}) \geq 0\)</span>，并且<span class="math inline">\(\mathbf{x} \in \Omega\)</span>。</p></blockquote><h2 id="凸优化的fons">凸优化的FONS</h2><p>1、约束：对于所有的可行方向<span class="math inline">\(\mathbf{d}\)</span>，都有<span class="math inline">\(\mathbf{d}^{T} \nabla f\left(\mathbf{x}^{*}\right) \geq 0\)</span>。</p><p>2、<span class="math inline">\(\nabla f\left(\mathbf{x}^{*}\right)=0\)</span>。</p><p>3、满足朗格朗日条件<span class="math inline">\(\Omega=\{\mathbf{x}: \mathbf{h}(\mathbf{x})=0\}\)</span>。</p><p>4、满足KKT条件<span class="math inline">\(\Omega=\{\mathbf{x}: \mathbf{h}(\mathbf{x})=0, \mathbf{g}(\mathbf{x}) \leq 0\}\)</span>。</p></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> 陶文寅</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="/bearcoding.cn/optimization-theory-applications/" title="优化理论和应用">bearcoding.cn/optimization-theory-applications/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/data-preprocessing/" rel="next" title="数据预处理-数据转换"><i class="fa fa-chevron-left"></i> 数据预处理-数据转换</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/ros-anaconda/" rel="prev" title="Anaconda环境下的ROS配置">Anaconda环境下的ROS配置<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#介绍"><span class="nav-number">1.</span> <span class="nav-text">介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化问题"><span class="nav-number">1.1.</span> <span class="nav-text">优化问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性规划问题"><span class="nav-number">1.2.</span> <span class="nav-text">线性规划问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#整数线性规划问题"><span class="nav-number">1.2.1.</span> <span class="nav-text">整数线性规划问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最小二乘问题"><span class="nav-number">1.3.</span> <span class="nav-text">最小二乘问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#凸优化问题"><span class="nav-number">1.4.</span> <span class="nav-text">凸优化问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#优化模型分类"><span class="nav-number">1.5.</span> <span class="nav-text">优化模型分类</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基础知识"><span class="nav-number">2.</span> <span class="nav-text">基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#符号说明"><span class="nav-number">2.1.</span> <span class="nav-text">符号说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性相关"><span class="nav-number">2.2.</span> <span class="nav-text">线性相关</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二次型函数"><span class="nav-number">2.3.</span> <span class="nav-text">二次型函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#二次规划"><span class="nav-number">2.3.1.</span> <span class="nav-text">二次规划</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性规划最优控制"><span class="nav-number">2.3.2.</span> <span class="nav-text">线性规划最优控制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵"><span class="nav-number">2.4.</span> <span class="nav-text">矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#矩阵范数"><span class="nav-number">2.4.1.</span> <span class="nav-text">矩阵范数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线性方程"><span class="nav-number">2.4.2.</span> <span class="nav-text">线性方程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#内积"><span class="nav-number">2.4.3.</span> <span class="nav-text">内积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征值和特征矩阵"><span class="nav-number">2.4.4.</span> <span class="nav-text">特征值和特征矩阵</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#几何概念"><span class="nav-number">2.5.</span> <span class="nav-text">几何概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线段"><span class="nav-number">2.5.1.</span> <span class="nav-text">线段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#超平面"><span class="nav-number">2.5.2.</span> <span class="nav-text">超平面</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#凸集"><span class="nav-number">2.5.3.</span> <span class="nav-text">凸集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#凸包"><span class="nav-number">2.5.4.</span> <span class="nav-text">凸包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#领域"><span class="nav-number">2.5.5.</span> <span class="nav-text">领域</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#微积分"><span class="nav-number">2.6.</span> <span class="nav-text">微积分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#水平集和梯度"><span class="nav-number">2.7.</span> <span class="nav-text">水平集和梯度</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#无约束优化问题"><span class="nav-number">3.</span> <span class="nav-text">无约束优化问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#局部极小点x"><span class="nav-number">3.1.</span> <span class="nav-text">局部极小点x</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#可行方向"><span class="nav-number">3.2.</span> <span class="nav-text">可行方向</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#方向导数"><span class="nav-number">3.2.1.</span> <span class="nav-text">方向导数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fonc一阶必要条件"><span class="nav-number">3.2.2.</span> <span class="nav-text">FONC（一阶必要条件）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sonc二阶必要条件"><span class="nav-number">3.2.3.</span> <span class="nav-text">SONC（二阶必要条件）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sosc二阶充分条件"><span class="nav-number">3.2.4.</span> <span class="nav-text">SOSC（二阶充分条件）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#一维搜索方法"><span class="nav-number">4.</span> <span class="nav-text">一维搜索方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍-1"><span class="nav-number">4.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#泰勒公式"><span class="nav-number">4.2.</span> <span class="nav-text">泰勒公式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#牛顿法牛顿切线法"><span class="nav-number">4.3.</span> <span class="nav-text">牛顿法（牛顿切线法）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#牛顿优化法"><span class="nav-number">4.4.</span> <span class="nav-text">牛顿优化法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#割线法"><span class="nav-number">4.5.</span> <span class="nav-text">割线法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多维优化问题中的一维搜索"><span class="nav-number">4.6.</span> <span class="nav-text">多维优化问题中的一维搜索</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度方法"><span class="nav-number">5.</span> <span class="nav-text">梯度方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍-2"><span class="nav-number">5.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最速下降法"><span class="nav-number">5.2.</span> <span class="nav-text">最速下降法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#牛顿法"><span class="nav-number">6.</span> <span class="nav-text">牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本思想"><span class="nav-number">6.1.</span> <span class="nav-text">基本思想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#牛顿法没有步阶大小或者步阶为1"><span class="nav-number">6.2.</span> <span class="nav-text">牛顿法（没有步阶大小，或者步阶为1）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#levenberg-marquardt修正"><span class="nav-number">6.3.</span> <span class="nav-text">Levenberg-Marquardt修正</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#牛顿法总结"><span class="nav-number">6.4.</span> <span class="nav-text">牛顿法总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#共轭方向法"><span class="nav-number">7.</span> <span class="nav-text">共轭方向法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍-3"><span class="nav-number">7.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#共轭向量"><span class="nav-number">7.2.</span> <span class="nav-text">共轭向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#共轭方向算法"><span class="nav-number">7.3.</span> <span class="nav-text">共轭方向算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#共轭梯度法"><span class="nav-number">7.4.</span> <span class="nav-text">共轭梯度法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#共轭梯度法在非二次型问题"><span class="nav-number">7.4.1.</span> <span class="nav-text">共轭梯度法在非二次型问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#拟牛顿法"><span class="nav-number">8.</span> <span class="nav-text">拟牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#回顾牛顿法"><span class="nav-number">8.1.</span> <span class="nav-text">回顾牛顿法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本思想-1"><span class="nav-number">8.2.</span> <span class="nav-text">基本思想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#拟牛顿法-1"><span class="nav-number">8.3.</span> <span class="nav-text">拟牛顿法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#秩1法"><span class="nav-number">8.4.</span> <span class="nav-text">秩1法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dfp算法变尺度算法"><span class="nav-number">8.5.</span> <span class="nav-text">DFP算法（变尺度算法）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bfgs算法"><span class="nav-number">8.6.</span> <span class="nav-text">BFGS算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性规划"><span class="nav-number">9.</span> <span class="nav-text">线性规划</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#标准型线性规划"><span class="nav-number">9.1.</span> <span class="nav-text">标准型线性规划</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#不等式约束的情况"><span class="nav-number">9.2.</span> <span class="nav-text">不等式约束的情况</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#转化为标准型松弛变量"><span class="nav-number">9.2.1.</span> <span class="nav-text">转化为标准型：松弛变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#转化为标准型剩余变量"><span class="nav-number">9.2.2.</span> <span class="nav-text">转化为标准型：剩余变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#转化为标准型非正变量"><span class="nav-number">9.2.3.</span> <span class="nav-text">转化为标准型：非正变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#转化为标准型自由变量"><span class="nav-number">9.2.4.</span> <span class="nav-text">转化为标准型：自由变量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本解决方案"><span class="nav-number">9.3.</span> <span class="nav-text">基本解决方案</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基本解的性质"><span class="nav-number">9.4.</span> <span class="nav-text">基本解的性质</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#几何视角下的线性规划"><span class="nav-number">9.5.</span> <span class="nav-text">几何视角下的线性规划</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#整数规划问题"><span class="nav-number">10.</span> <span class="nav-text">整数规划问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#整数线性规划"><span class="nav-number">10.1.</span> <span class="nav-text">整数线性规划</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#解决ilp的方法"><span class="nav-number">10.2.</span> <span class="nav-text">解决ILP的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#幺模矩阵"><span class="nav-number">10.3.</span> <span class="nav-text">幺模矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#割平面法"><span class="nav-number">10.4.</span> <span class="nav-text">割平面法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主要思想"><span class="nav-number">10.4.1.</span> <span class="nav-text">主要思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流程"><span class="nav-number">10.4.2.</span> <span class="nav-text">流程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#仅含等式约束的优化问题重新看"><span class="nav-number">11.</span> <span class="nav-text">仅含等式约束的优化问题（重新看）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#拉格朗日条件"><span class="nav-number">11.1.</span> <span class="nav-text">拉格朗日条件</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#含不等式约束的优化问题"><span class="nav-number">12.</span> <span class="nav-text">含不等式约束的优化问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#凸优化问题-1"><span class="nav-number">13.</span> <span class="nav-text">凸优化问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#证明omegamathbfx-mathbfx-geq-0是凸集"><span class="nav-number">13.1.</span> <span class="nav-text">证明\(\Omega=\{\mathbf{x}: \mathbf{x} \geq 0\}\)是凸集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#凸方程"><span class="nav-number">13.2.</span> <span class="nav-text">凸方程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#验证二次型的凸函数"><span class="nav-number">13.3.</span> <span class="nav-text">验证二次型的凸函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#凸函数的另一个解释"><span class="nav-number">13.4.</span> <span class="nav-text">凸函数的另一个解释</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#凸优化的fons"><span class="nav-number">13.5.</span> <span class="nav-text">凸优化的FONS</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">陶文寅</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">39</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">11</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">15</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="/mailto:wenyin.tao@163.com" title="E-Mail &amp;rarr; mailto:wenyin.tao@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> E-Mail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">陶文寅</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script></body></html>