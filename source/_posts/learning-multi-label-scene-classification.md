---
title: 【2004】Learning multi-label scene classification
mathjax: true
date: 2020-03-07 15:29:17
updated: {{ date }}
tags: [多标签学习, 机器学习]
categories: [论文, 多标签学习]
---

# 摘要

在分类模式识别中，各个类通常是互斥的，并且是提前定义好的。当类在特征空间中重叠时会容易发生分类错误。作者研究一种不同的情况，即类之间并不是互斥。这种情况出现在语义场景和文档分类以及医学诊断中。我们提出了一个框架来处理这些问题，并将其应用到语义场景分类问题中，其中一个自然场景可能包含多个对象，使得场景可以由多个类标签来描述。作者提出了一个框架来处理这些问题，并将其应用到语义场景分类问题中，每个自然场景可能包含多个对象，使得场景可以由多个类标签来描述。这一问题对经典的模式识别范式提出了挑战，需要更深入的研究。作者讨论了在这种情况下场景训练和测试的方法，并介绍了评估单个示例、类召回和精确性以及总体精确性的新指标。实验表明，我们的方法适用于场景分类，而且，我们的工作似乎可以推广到其他性质相同的分类问题。

# 多标签分类

本节作者将表述一个训练和测试多标签数据可能的方法。使用“ $+$ ”和“$\times$”分别表示两类数据，如果实例同时属于“$+$”和“$\times$”，那么该实例就用“$\ast$”表示。

## 多标签的训练模型

对于多标签分类，首先要解决的问题就是如何进行训练。具体来说，就是如何在训练阶段对带有多标签的实例进行训练。

在前期的工作中，研究人员会根据主管判断，把多标签数据标记为更像的那一类。例如，如果海滩覆盖了图像的大部分，或者在数据收集时碰巧有人在寻找海滩场景，则有海滩沿线酒店的图像将被标记为海滩。如果在作者的实例中，“$\ast$”中的一部分数据将会被标记为“$+$”，另一部分被标记为“$\times$”。作者把这种模型称为$Model-s$（$s$表示“单标签”类）。

另一个可能的方式是当训练数据时，只是简单的忽略多标签数据。如果在作者的实例中，那么所有的“$\ast$”号数据都会被丢弃。作者把这种模型称为$Model-i$（$i$表示“忽略”的意思）。

要实现对每类数据的正确分类，最简单的方法就是将带有多标签的数据（“$\ast$”类）视为一个新类，并为这个新类构建一个模型。作者把这种模型称为$Model-n$（$n$表示“新”类的意思）。但是，这种方法有个严重的问题就是属于多标签的数据类在构建模型时会非常稀疏。表1展示了作者训练数据的图像种类。属于一个以上类别的图像数量占整个数据集的7%以上，但很多类别的数量非常小。当有些场景被赋予一个以上的类别时，这是一个重要的问题。

表1：数据集

| 编号 | 类别 | 训练图片 | 测试图片 | 合计 |
| :---: | :---: | :---: | :---: | :---: |
| 0 | 海滩（Beach） | 194 | 175 | 369 |
| 1 | 日落（Sunset） | 165 | 199 | 364 |
| 2 | 落叶（Fall foliage） | 184 | 176 | 360 |
| 3 | 田（Field） | 161 | 166 | 327 |
| 0,3 | 海滩$+$田（Beach$+$Field） | 0 | 1 | 1 |
| 2,3 | 落叶$+$田（Fall foliage$+$Field） | 8 | 16 | 23 |
| 4 | 山（Mountain） | 223 | 182 | 405 |
| 0,4 | 海滩$+$山（Beach$+$Mountain） | 21 | 17 | 38 |
| 2,4 | 落叶$+$山（Fall foliage$+$Mountain） | 5 | 8 | 13 |
| 3,4 | 田$+$山（Field$+$Mountain） | 26 | 49 | 75 |
| 2,3,4 | 田$+$落叶$+$山（Field$+$Fall foliage$+$Mountain） | 1 | 0 | 1 |
| 5 | 城市（Urban） | 210 | 195 | 405 |
| 0,5 | 海滩$+$城市（Beach$+$Urban） | 12 | 7 | 19 |
| 3,5 | 田$+$城市（Field$+$Urban） | 1 | 5 | 6 |
| 4,5 | 山$+$城市（Mountain$+$Urban） | 1 | 5 | 6 |
|  | 合计 | 1211 | 1196 | 2407 |

一种新的方法是在训练时多次使用多标签数据，使用每个示例作为它所属的每个类的正示例。在作者的实例中，作者认为当训练“$+$”模型时，那么“$\ast$”就属于“$+$”类，当训练“$\times$”模型时，那么“$\ast$”就属于“$+$”类。需要注意的时，“$\ast$”并不是作为“$+$”或者“$\times$”数据的反例。作者称这种方式为“交叉训练”。生成的类决策曲面如图3所示。在区域A中同时包含了“$+$”类和“$\times$”类。当对A区域的测试图像进行分类时，模型“$+$”和“$\times$”应将其分类为自己所属的类。按照测试标签准则，图像将有“$+$”和“$\times$”这两个标签。这个方法解决了稀疏数据的问题，因为作者使用了每个模型的相关数据。与$Model-n$这个训练方法相比较，交叉训练能够更加有效的使用训练数据，因为交叉训练模型比$Model-n$模型包含更多的训练数据。试验表明，交叉训练在多标签分类中是有效的。作者把这种方法称作$Model-x$（$x$表示交叉训练）。

{% asset_img cross-training.png 交叉训练说明 %}

图3：交叉训练说明

有人说交叉训练模型可能会给具有多标签的实例带来更多的权重。如果使用基于密度估计的分类器（如ANN），那么确实会如此。作者认识到，使用每个类别都有输出节点的神经网络来处理多标签分类也是很自然的。但是，作者在他的研究中使用了SVM模型，该模型在场景分类和文本分类中具有更高的精度和更好的泛化性。直观地说，多标签图像很可能是那些接近决策边界的图像，这使得它们对于支持向量机类型分类器特别有价值。在实际应用中，多标签图像的稀疏性也使得使用这些图像成为必然。如果图像中存在多个分类，那么就可需要通过标签分布来进行采样来。

## 多标签的测试准则

在本节中，作者将讨论用于测试的多标签准则。如上所述，一些类组合的稀疏性使得在构建模型时，不会为每个多标签构建禁止我们构建$Model-n$模型。因此，作者基于基础类别进行模型的构建。作者接下来将讨论如果通过基类模型输出来获取多标签。

为了简化作者的讨论，作者使用SVM作为实例的分类器。在一对多方法中，为每个基础类训练一个分类器，并在每个分类器上输出测试示例的分数。这些分数能够通过一个逻辑函数映射为一个伪概率，这些输出的值能够被认为是测试实例相应类别的置信度。

对于标准的二分类SVM，如果实例的SVM值为正，那么该实例就标记为正例。在一对多的方法中，如果SVM输出了多个正值，那么实例会根据SVM输出的最大值的类别来标记对应的分类。对于一些实例也可能，可能由于特征的缺失，使得有的SVM输出为负值。

为了把一对多方法扩展到多标签分类中，作者使用下面三个标记准则来进行实验。

>* P准则：把SVM输出为正值的测试数据都标记为相应的分类。如果输出值都是负值，那么就把测试数据标记为“未知”。（“P”表示正值的意思）
>
>* T准则：与P准则类似，但在处理SVM输出值都为负值的实例上有所不同。假如所有的SVM输出都为负值，那么就把测试实例标记为输出值最大的那个对应的分类。（“T”表示最大的意思）
>
>* C准则：决定一个实例是否标记为某个标签，依赖于SVM分数最高的几个成绩之间的接近程度，而与得分的正、负无关。如果对于某个实例来说，如果前$M$个分数足够的接近，那么这些分数对因的标签就是该实例的标签。**作者使用最大后验概率（MAP）来确定一个阈值**，该阈值的作用就是判断SVM的输出值是否足够的接近。（“C”表示接近的意思）

使用两个类别来形式化C准则，并进行说明：

给定一个实例$x$，并且两个SVM分类器分别输出对于两个分类$c_{1}$和$c_{2}$的两个值$s_{1}$和$s_{2}$。假设$s_{1}>s_{2}$，并且$dif=s_{1}-s_{2}>0$。那么问题是，实例$x$是标记为$c_{1}$，还是表示为$c_{1}$和$c_{2}$。

作者使用最大后验概率（MAP）来解决这个问题：

假设$E_{1}$：实例$x$只有一个标签$c_{1}$的事件。

假设$E_{2}$：实例$x$有两个标签$c_{1}$和$c_{2}$的事件。

那么最大后验概率MAP可以表示为

$$\begin{aligned}
E &=\arg \max _{i} p\left(E_{i} | dif\right) \\
&=\arg \max _{i} p\left(E_{i}\right) \cdot p\left(dif | E_{i}\right)
\end{aligned}$$

其中$p\left(dif | E_{i}\right)$的概率能够通过训练数据计算得到。利用交叉训练得到的SVM模型对训练图像进行分类。$DIF_{1}$和$DIF_{2}$两个不同的集合，具体如下：

>* $DIF_{1}$：对于每个正确标记的单类训练图像，前两个SVM得分之间的差异集合。
>
>* $DIF_{2}$：每个多类图像对应多个类的支持向量机得分之间的差异集。

作者将Gamma分布拟合到这两个集合，因为数据是非负的，而且它可能是最佳拟合。图4就展示了在实验过程中两个不同的数据集直方图和分布。图4（c）展示了通过将Gamma分布与直方图拟合得到这两个分布。图4（d）展示了把（c）中的分布乘以$p\left(E_{i}\right)$得到曲线。交叉点$T_{x}$的$x$轴就是所需的阈值。假如两个SVM的差值比$T_{x}$大，那么$E=E_{1}$，即属于分类$c_{1}$，否则$E=E_{2}$，即属于$c_{1}$和$c_{2}$分类。

{% asset_img threshold-determination.png 两个不同数据集的直方图和分布 %}

图4：C准则下的阈值确定的直方图和分布。（a）$DIF_{1}$的直方图；（b）$DIF_{2}$的直方图；（c）$p\left(dif | E_{1}\right)$和$p\left(dif | E_{2}\right)$分布曲线（d）$p\left(E_{1}\right) \cdot p\left(dif | E_{1}\right)$和$p\left(E_{2}\right) \cdot p\left(dif | E_{2}\right)$分布曲线

选择$T_{x}$作为判断的阈值，可以将模型的分类误差最小化。给定任意阈值$T$，分类误差如图5中的阴影区域。只有当阈值$T$是两条曲线的交点时，着色区域的面积才最小化，即$p\left(E_{1}\right) * p\left(dif | E_{1}\right)=p\left(E_{2}\right) * p\left(dif | E_{2}\right)$

{% asset_img decision-error.png 使用阈值$T$的决策误差 %}

图5：使用阈值$T$的决策误差

# 多标签分类结果的评价

多标签分类的性能评价不同于但标签分类的性能评价。标准的评价指标包括准确度、召回率、精度和F指标。在多标签分类中，评价更为复杂，因为结果可能完全正确或者部分正确或者完全错误。以属于$c_{1}$和$c_{2}$类的实例为例。可以得到如下中的一个结果

1、$c_{1}$和$c_{2}$（完全正确）

2、$c_{1}$（完全正确）

3、$c_{1}$和$c_{3}$（部分正确）

4、$c_{1}$、$c_{3}$和$c_{4}$（部分正确）

5、$c_{3}$$和$c_{4}$（完全错误）

以上五个结果的正确性程度不同。

Schapire和Singer使用了三种度量方式，都是为排序任务所定制的：One-error，覆盖率和精度。精度是一种可以用来评估整个系统的测量方法。

$$\operatorname{precision}_{S}(h)=\frac{1}{m} \sum_{i=1}^{m} \frac{1}{\left|Y_{i}\right|} \sum_{l \in Y_{i}} \frac{\left|\left\{l^{\prime} \in Y_{i} | \operatorname{rank}_{h}\left(x_{i}, l^{\prime}\right) \leqslant \operatorname{rank}_{h}\left(x_{i}, l\right)\right\}\right|}{\operatorname{rank}_{h}\left(x_{i}, l\right)}$$

其中$h$表示分类器，$S$表示训练集，$m$是所有测试集的数量，$Y_{i}$是一个测试实例的标准标签集，$x_{i}$是测试的实例，$\operatorname{rank}_{h}\left(x_{i}, l^{\prime}\right)$是关于实例$x_{i}$的预测分类器$h$输出关于标签$l$的排序。

作者提供2个新方法来评价多标签分类系统

## $\alpha$评价

## 基于类别的评价