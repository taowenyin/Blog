---
title: 【2004】Learning multi-label scene classification
mathjax: true
date: 2020-03-07 15:29:17
updated: {{ date }}
tags: [多标签学习, 机器学习]
categories: [论文, 多标签学习]
---

# 摘要

在分类模式识别中，各个类通常是互斥的，并且是提前定义好的。当类在特征空间中重叠时会容易发生分类错误。作者研究一种不同的情况，即类之间并不是互斥。这种情况出现在语义场景和文档分类以及医学诊断中。我们提出了一个框架来处理这些问题，并将其应用到语义场景分类问题中，其中一个自然场景可能包含多个对象，使得场景可以由多个类标签来描述。作者提出了一个框架来处理这些问题，并将其应用到语义场景分类问题中，每个自然场景可能包含多个对象，使得场景可以由多个类标签来描述。这一问题对经典的模式识别范式提出了挑战，需要更深入的研究。作者讨论了在这种情况下场景训练和测试的方法，并介绍了评估单个示例、类召回和精确性以及总体精确性的新指标。实验表明，我们的方法适用于场景分类，而且，我们的工作似乎可以推广到其他性质相同的分类问题。

# 多标签分类

本节作者将表述一个训练和测试多标签数据可能的方法。使用“ $+$ ”和“$\times$”分别表示两类数据，如果实例同时属于“$+$”和“$\times$”，那么该实例就用“$\ast$”表示。

## 多标签的训练模型

对于多标签分类，首先要解决的问题就是如何进行训练。具体来说，就是如何在训练阶段对带有多标签的实例进行训练。

在前期的工作中，研究人员会根据主管判断，把多标签数据标记为更像的那一类。例如，如果海滩覆盖了图像的大部分，或者在数据收集时碰巧有人在寻找海滩场景，则有海滩沿线酒店的图像将被标记为海滩。如果在作者的实例中，“$\ast$”中的一部分数据将会被标记为“$+$”，另一部分被标记为“$\times$”。作者把这种模型称为$Model-s$（$s$表示“单标签”类）。

另一个可能的方式是当训练数据时，只是简单的忽略多标签数据。如果在作者的实例中，那么所有的“$\ast$”号数据都会被丢弃。作者把这种模型称为$Model-i$（$i$表示“忽略”的意思）。

要实现对每类数据的正确分类，最简单的方法就是将带有多标签的数据（“$\ast$”类）视为一个新类，并为这个新类构建一个模型。作者把这种模型称为$Model-n$（$n$表示“新”类的意思）。但是，这种方法有个严重的问题就是属于多标签的数据类在构建模型时会非常稀疏。表1展示了作者训练数据的图像种类。属于一个以上类别的图像数量占整个数据集的7%以上，但很多类别的数量非常小。当有些场景被赋予一个以上的类别时，这是一个重要的问题。

表1：数据集

| 编号 | 类别 | 训练图片 | 测试图片 | 合计 |
| :---: | :---: | :---: | :---: | :---: |
| 0 | 海滩（Beach） | 194 | 175 | 369 |
| 1 | 日落（Sunset） | 165 | 199 | 364 |
| 2 | 落叶（Fall foliage） | 184 | 176 | 360 |
| 3 | 田（Field） | 161 | 166 | 327 |
| 0,3 | 海滩$+$田（Beach$+$Field） | 0 | 1 | 1 |
| 2,3 | 落叶$+$田（Fall foliage$+$Field） | 8 | 16 | 23 |
| 4 | 山（Mountain） | 223 | 182 | 405 |
| 0,4 | 海滩$+$山（Beach$+$Mountain） | 21 | 17 | 38 |
| 2,4 | 落叶$+$山（Fall foliage$+$Mountain） | 5 | 8 | 13 |
| 3,4 | 田$+$山（Field$+$Mountain） | 26 | 49 | 75 |
| 2,3,4 | 田$+$落叶$+$山（Field$+$Fall foliage$+$Mountain） | 1 | 0 | 1 |
| 5 | 城市（Urban） | 210 | 195 | 405 |
| 0,5 | 海滩$+$城市（Beach$+$Urban） | 12 | 7 | 19 |
| 3,5 | 田$+$城市（Field$+$Urban） | 1 | 5 | 6 |
| 4,5 | 山$+$城市（Mountain$+$Urban） | 1 | 5 | 6 |
|  | 合计 | 1211 | 1196 | 2407 |

一种新的方法是在训练时多次使用多标签数据，使用每个示例作为它所属的每个类的正示例。在作者的实例中，作者认为当训练“$+$”模型时，那么“$\ast$”就属于“$+$”类，当训练“$\times$”模型时，那么“$\ast$”就属于“$+$”类。需要注意的时，“$\ast$”并不是作为“$+$”或者“$\times$”数据的反例。作者称这种方式为“交叉训练”。生成的类决策曲面如图3所示。在区域A中同时包含了“$+$”类和“$\times$”类。当对A区域的测试图像进行分类时，模型“$+$”和“$\times$”应将其分类为自己所属的类。按照测试标签准则，图像将有“$+$”和“$\times$”这两个标签。这个方法解决了稀疏数据的问题，因为作者使用了每个模型的相关数据。与$Model-n$这个训练方法相比较，交叉训练能够更加有效的使用训练数据，因为交叉训练模型比$Model-n$模型包含更多的训练数据。试验表明，交叉训练在多标签分类中是有效的。作者把这种方法称作$Model-x$（$x$表示交叉训练）。

{% asset_img cross-training.png 交叉训练说明 %}

图3：交叉训练说明

有人说交叉训练模型可能会给具有多标签的实例带来更多的权重。如果使用基于密度估计的分类器（如ANN），那么确实会如此。作者认识到，使用每个类别都有输出节点的神经网络来处理多标签分类也是很自然的。但是，作者在他的研究中使用了SVM模型，该模型在场景分类和文本分类中具有更高的精度和更好的泛化性。直观地说，多标签图像很可能是那些接近决策边界的图像，这使得它们对于支持向量机类型分类器特别有价值。在实际应用中，多标签图像的稀疏性也使得使用这些图像成为必然。如果图像中存在多个分类，那么就可需要通过标签分布来进行采样来。

## 多标签的测试准则

在本节中，作者将讨论用于测试的多标签准则。如上所述，一些类组合的稀疏性使得在构建模型时，不会为每个多标签构建禁止我们构建$Model-n$模型。因此，作者基于基础类别进行模型的构建。作者接下来将讨论如果通过基类模型输出来获取多标签。

为了简化作者的讨论，作者使用SVM作为实例的分类器。在一对多方法中，为每个基础类训练一个分类器，并在每个分类器上输出测试示例的分数。这些分数能够通过一个逻辑函数映射为一个伪概率，这些输出的值能够被认为是测试实例相应类别的置信度。

对于标准的二分类SVM，如果实例的SVM值为正，那么该实例就标记为正例。在一对多的方法中，如果SVM输出了多个正值，那么实例会根据SVM输出的最大值的类别来标记对应的分类。对于一些实例也可能，可能由于特征的缺失，使得有的SVM输出为负值。

为了把一对多方法扩展到多标签分类中，作者使用下面三个标记准则来进行实验。

>* P准则：把SVM输出为正值的测试数据都标记为相应的分类。如果输出值都是负值，那么就把测试数据标记为“未知”。（“P”表示正值的意思）

>* T准则：与P准则类似，但在处理SVM输出值都为负值的实例上有所不同。假如所有的SVM输出都为负值，那么就把测试实例标记为输出值最大的那个对应的分类。（“T”表示最大的意思）

>* C准则：