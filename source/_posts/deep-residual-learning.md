---
title: 【2016】Deep Residual Learning for Image Recognition
mathjax: true
date: 2020-05-19 09:28:20
updated: {{ date }}
tags: [深度学习]
categories: [论文]
---

# 摘要

深度神经网络越来越难训练。作者提出了一种残差学习框架，该框架能够简化那些非常深的网络训练。该框架使得网路层能够根据其输入来学习残差函数，而非原始函数。通过全面的试验表明，残差网络能够更加容易的优化，并且能够从较深的网络中获取更好的精度。在ImageNet数据集上，作者对152层的残差网络进行了评价，虽然该网络是VGG网络深度的8倍，但是仍然具有较低的复杂性。一个残差网络的组合模型在ImageNet的测试集上达到了3.57%的错误率。这个结果在ILSVRC2015的分类分类任务中取得了第一名。同时，我们也分析了在CIFAR-10数据集上100层和1000层的残差网络。

表达的深度在很多视觉识别任务中是至关重要的。仅仅只是采用了较深的表达，便在COCO目标检测数据集上获得28%的性能提升。深度残差网络是作者参加ILSVRC和COCO2015竞赛上所使用的模型基础，且作者在ImageNet检测、ImageNet定位、COCO检测以及COCO分割上均获得了第一名的成绩。

# 介绍

深度卷积神经网络在图像分类上取得了一系列的突破。深度网络以端到端的多层方式很好的集成了低、中、高层的的特征和分类器，特征的层次可以通过多层的堆叠来丰富。最近的研究表明，网络的深度是至关重要的，在具有挑战性的ImageNet数据集上，最好的结果都采用了16-30层深度的网络模型。此外，许多有难度的视觉识别任务也能够从非常深的模型上获得较好的结果。

**在网络深度的驱使下，一个新的问题产生了：训练一个更好的网络是不是就像堆叠更多的网络层一样容易？** 回答这个问题的障碍就是困扰人们很久的梯度消失/梯度爆炸问题，这个问题从一开始就阻止了模型的收敛。然而，这个问题已经在很大程度上通过归一化和中间归一化层得到了解决，使得数十层的网络能够通过反向传播的随即梯度下降能够是进行收敛。

当深度网络开始收敛时，退化问题又暴露了出来：随着网络深度的增加，模型的精度会饱和（这并不奇怪），然后迅速的退化。出乎意料的是，这种退化并不是过拟合造成的，并且当向模型增加更多层时会造成更高的错误率。作者的实验也证明了这一点，图1是一个典型的例子。

{% asset_img training-error.png 训练与测试误差 %}

图1：在CIFAR-10数据集上20层和56层普通网络的训练误差（左）和测试误差（右）。更深的网络有更高的训练误差和测试误差。在ImageNet数据集上有类似现象，如图4所示。

退化的出现表示并非所有的系统都容易被优化。作者比较了一个网络的浅层结构和对应的深层结构。有一个解决方案可以构建更深的模型：添加一个**恒等映射层**，而其他层则直接从浅层模型映射过来。这个结构的深度模型表示一个深度模型不应该有比浅层网络更高的错误率。但是实现表明，作者目前无法找到一个与这种构建的解决方案相当或者更好的方案（或者说无法在可行的时间内实现）。

在本论文中，作者通过引入了**深度残差网络框架** 解决了退化问题。我们明确的让这些层来拟合残差映射，而不是让每一个堆叠的层直接来拟合所需的底层映射。形式上，假设所需的底层映射为$\mathcal{H}(\mathbf{x})$，作者让叠加的非线性层拟合另一个映射$\mathcal{F}(\mathbf{x}):=\mathcal{H}(\mathbf{x})-\mathbf{x}$。那么原始映射就被重新转化为$\mathcal{F}(\mathbf{x})+\mathbf{x}$。作者推断残差映射比原始未参考的印社更容易优化。在极端情况下，如果一个恒等映射是最优的，那么把残差优化为0比通过堆叠线性层来拟合恒等要更加容易。

式子中的$\mathcal{F}(\mathbf{x})+\mathbf{x}$能够通过有“快捷连接”的前向神经网络来实现（如图2所是）。“快捷连接”能够跳过一个或多个网路层。在作者的例子中。“快捷连接”的作用只是简单的执行恒等映射，并“快捷连接”的输出被添加到堆叠的网络层的输出上。恒等映射的“快捷连接”并没有增加额外的参数和计算复杂度。整个网络依然可以通过反向传播SGD实现端到端的训练，并且可以在不修改求解器的情况下使用公共库来轻松实现。

{% asset_img building-block.png 残差学习 %}

图2：残差学习：一个基本结构

作者在ImageNet上进行了全面的实验，以显示退化问题，并评估作者的方法。通过实验表明：1）作者的深度残差网络可以很容易的优化，而相应“普通”网络（通过简单的堆叠层）在深度增加时表现出更高的训练误差。2）作者的深度残差网络能够很容易的从网络深度大幅增加中获得精度增益，而产生的结果比以前的网络要好得多。

CIFAR-10数据集中也有类似的现象，这表明了作者提出的方法的优化难度和效果并不仅仅是对于一个特定数据集。作者在这个数据集上成功的提出了超过100层的训练模型，并探索了超过1000层的模型。

在ImageNet分类数据集上，作者通过极深的残差网络获得了很好的结果。作者的152层残差网络是ImageNet上出现的最深的网络，但其复杂度仍然低于VGG网络。作者的组合模型的top-5错误率仅为3.57%，并赢得了ILSVRC 2015分类竞赛的第一名。在其他识别人物中，极深的模型也表现出很好的泛化性能，使的作者在ILSVRC和COCO 2015比赛中进一步赢得了ImageNet检测、ImageNet定位、COCO检测和COCO分割的第一名。这有利的证据表明，残差学习的原理是通用的，作者期待它能够用于其他视觉问题和非视觉问题中。

# 相关工作

**残差表达：** 在图像识别中，VLAD是残差向量对应于字典进行编码的一种表达形式，并且Fisher向量可以看做是VLAD的一个概率版本。对于图像的检索和分类具有强力的浅层表达。对于向量量化，残差向量编码比原始向量的编码更为有效。

在低级视觉和计算机图形学中，为了求解偏微分方程，通常使用Multigrid方法将系统重新表达为多尺度的子问题来解决，其中每个子问题又是解决粗细尺度之间的残差问题。Multigrid的另一个形式是分层基预处理，它依赖于两个尺度之间的残差向量的变量。实验证明，这些求解器的收敛速度要比标准的求解器快得多，却没有意识到该方法快的原因是残差特性导致的。这些方法表明一个好的重新表达或者预处理可以很容易的进行优化。

**快捷连接：** 快捷连接的实践和理论已经研究了很长时间。快捷连接早期在多层感知机训练上的研究是添加一个线性层，把网络输入与输出进行连接。在相关文献中，一些中间层直接到辅助分类器来处理梯度爆炸/消失。还有文献提出了通过快捷连接实现层响应、梯度、传播误差的中心化方法。还有文献，提出了有一个快捷分支和一些较深分支组成的“inception”层。

在作者工作的同时，“高速网络”提供了门控功能的快捷连接。这些门控依赖于数据，并且需要一些参数，而作者的恒等快捷连接则不需要参数。当一个快捷门控关闭时（接近于0），高速网络中的层表现为非残差函数。恰恰相反，作者的形式总是一个残差函数，恒等快捷也不会关闭，并且在学习额外的残差函数时，所有的信息都能够通过。此外，“高速网络”没有显示出当网络深度增加时（例如，超过100层）带来的精度提高。

# 深度残差学习

## 残差学习

作者将$\mathcal{H}(\mathbf{x})$认为是一个由部分堆叠层（不必是整个网络）来拟合的底层映射，而$\mathbf{x}$表示这个层的输入。如果加入多个非线性层能够逐渐逼近一个复杂函数，那么也相当于假设它们可以逐渐逼近一个残差函数，例如$\mathcal{H}(\mathbf{x})-\mathbf{x}$（假设输入和输出具有相同的纬度）。因此，作者希望这些堆叠层能显式的近似残差函数$\mathcal{F}(\mathbf{x}):=\mathcal{H}(\mathbf{x})-\mathbf{x}$，而不是近似底层映射$\mathcal{H}(\mathbf{x})$。因此原始函数就变为$\mathcal{F}(\mathbf{x})+\mathbf{x}$。虽然这种形式都应该可以逐渐逼近期望函数（假设成立），但学习的难易程度却不同。

这种重表达的动机是因为退化问题的反直觉现象（如图1，左）。正如作者在介绍里讨论的，如果增加的层能以恒等映射来构建，那么一个更深模型的训练错误率不应该比它对应的浅层模型更大。退化问题表明了一个求解器通过多个非线性层来近似恒等映射是困难的。而伴随着残差学习的重表达，如果恒等映射是最优的，那么求解器驱使多个非线性层的权重趋向于零来逼近恒等映射。

在真实的案例中，恒等映射不太可能是最优解，但是作者的重表达能够帮助解决这个问题。如果最优函数更趋近于恒等映射而不是0映射，那么对于求解器来说寻找关于恒等映射的扰动比学习一个新的函数要容易的多。通过实验（如图7所示），学习到的残差函数通常只有很小的响应，说明了恒等映射提供了合理的预处理。

## 通过快捷方式实现恒等映射

作者在每个堆叠层上采用残差学习。一个残差学习的模块如图2所示。从形式上说，在本论文中作者认为一个残差学习模块可以被定义为（式子1）：

$$\mathbf{y}=\mathcal{F}\left(\mathbf{x},\left\{W_{i}\right\}\right)+\mathbf{x}$$

这里的$\mathbf{x}$和$\mathbf{y}$分别表示每层的输入和输出向量。$\mathcal{F}\left(\mathbf{x},\left\{W_{i}\right\}\right)$表示已经学习的残差映射。在如图2的例子中有两个层，$\mathcal{F}=W_{2} \sigma\left(W_{1} \mathbf{x}\right)$，其中$\sigma$表示ReLU的激活函数，为了简化符号省略了偏置项。$\mathcal{F}+\mathbf{x}$通过快捷连接和元素加法来执行。在加法之后我们再执行另一个非线性操作（如图2所示的$\sigma(\mathbf{y})$）。

在式子1中的快捷连接既没有引入额外的参数也没有增加计算的复杂度。这不仅在实践中具有吸引力，而且在作者比较普通网络和残差网络时也非常重要。作者可以公平的同时比较在相同参数数量、深度、宽度和计算成本（除了可以忽略的元素加成）下的普通网络和残差网络。

在式子1中$\mathbf{x}$和$\mathcal{F}$的维度必须相同。如果不相同（如改变了输入、输出的通道数），那么就需要在快捷连接上执行一个线性映射$W_{s}$来匹配输入、输出的纬度（式子2）：

$$\mathbf{y}=\mathcal{F}\left(\mathbf{x},\left\{W_{i}\right\}\right)+W_{s} \mathbf{x}$$

在式子（1）中也可以使用方阵$W_{s}$。但是通过实验可以知道恒等映射已经足以解决退化问题，并且是经济的，因此$W_{s}$只是用来解决维度不匹配的问题。

残差函数的形式$\mathcal{F}$是很灵活的。在本论文中引入了一个有两层或三层的$\mathcal{F}$函数（如图5所示），当然更多层也是可行的。但如果$\mathcal{F}$只有一层，式子（1）就和线性函数$\mathbf{y}=W_{1} \mathbf{x}+\mathbf{x}$类似，因此也就不具有优势。

作者还发现不仅是对于全连接层，对于卷积层也是同样适用的。函数$\mathcal{F}\left(\mathbf{x},\left\{W_{i}\right\}\right)$可以表示多个卷积层。在两个特征图的通道之间执行元素级的加法。

## 网络结构

作者在多个普通网络和残差网络上进行了测试，并都观测到了一致的现象。接下来作者将在ImageNet上对两个模型进行讨论。

**普通网络：** 作者的普通网络结构（如图3所示，中间）是受VGG网络（如图3所示，左边）原理启发。巻积层一般使用$3 \times 3$巻积核，并且按照下面两个简单的设计规则：（1）对于相同的输出特征尺寸，那么层的巻积核的数量就是相同的；（2）如果将特征映射大小减半，则巻积核的数量将增加一倍，以保持每层的时间复杂性。作者直接通过步长为2的巻积层执行下采样。该网络以一个全局平均池层和一个1000通道的softmax层完全连接作为结束。图3（中间）中加权层的总数为34。

{% asset_img imagenet-model.png ImageNet网络结构实例 %}

图3：ImageNet网络结构实例。左边：VGG-19模型是一个参考。中间：有34个参数层的普通网络。右边：有34个参数层的残差网络。虚线表示的快捷连接表示增加维度。表1展示了更多细节和其他变体。

值得注意的是，作者的模型比VGG网络具有更少的巻积核和更低的复杂性（如图3所示，左边）。作者34层的结构含有36亿个FLOPs（乘-加），而该模型仅仅只有VGG-19 （196亿个FLOPs）的18%。

**残差网络：** 基于普通网络，作者插入了快捷连接（如图3所示，右边），将网络转化为对应的残差版本。当输入和输出具有相同维度时，恒等快捷连接（式子1）能够被直接使用（图3中的实线快捷连接）。当维度增加时（图3中的虚线快捷连接），作者认为可以有两个选项：（1）快捷连接继续执行恒等映射，通过添加0数组来填充增加的维度。该选项不增加额外参数；（2）使用式子（2）中的映射快捷连接来匹配维度（通过$1 \times 1$巻积）。对于这两个选项，当快捷连接跨越两种尺寸的特征图时，均使用步长为2的卷积。

## 实现

作者对ImageNet的实现遵循了文献中的实践。调整图像的大小使它的短边长度随机的从文献中采样来增大图像的尺寸。从图像或其水平翻转中随机采样224×224个裁剪，并减去每像素的平均值。使用文献中的标准颜色增强。作者在每次卷积之后和激活之前都采用批处理规范化（BN）。作者使用文献中的方法初始化权重，并从头开始训练所有的普通网络和残差网络。作者使用大小为256的mini-batch进行SGD。学习率从0.1开始，当误差趋于平稳时，学习率除以10，然后对模型进行高达$60 \times 10^{4}$次的迭代训练。作者还使用了0.0001的重量衰减和0.9的动量。按照文献中的做法，作者不使用dropout。

在测试中，为了进行比较研究，我们采用标准的10-crop测试。为了获得最好的结果，作者采用了文献中所示的完全巻积形式，并在多个尺度（调整图像大小，使较短的边位于{224，256，384，480，640}）的结果上取平均分。

# 实验

## ImageNet分类

## CIFA-10以及分析

## PASCAL和MS COCO的目标检测