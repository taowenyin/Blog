---
title: Multi-Label Learning with Deep Forest
mathjax: true
date: 2019-12-17 20:00:29
updated: {{ date }}
tags:
- 多标签学习
- 深度学习
categories: 
- 论文
---

# 摘要

在对标签学习中，每个实例都都与多个标签相关，因此多标签学习的关键就是在构建模型中如何利用标签之间的相关性。深度神经网络方法经常把特征和标签信息进行联合放到一个潜在的空间，从而挖掘出标签之间的相关性。然而，这些方法的成功高度依赖于模型深度的精确选择。深度森林（Deep Forest）是一个基于树模型集成的深度学习框架，并且不依赖于反向传播。作者认为深度森林模型的优势在于非常适合解决多标签问题。MLDF方法具有两个机制：

>* 度量感知特征重用机制：以置信度作为依据，重用前一层的较好标签。
>* 度量感知层增长机制：保证了MLDF模型复杂度随性能的度量而逐步增加。

MLDF将同时面对两个问题的挑战：

>* 通过限制模型的复杂度来防止过拟合的问题。
>* 因为在多标签任务中有许多不同的指标，所以需要根据用户需求优化性能指标。

实验表明，MLDF不仅优于在9个基准数据集上使用的6个方法，并且还能够在多标签学习中发现标签之间的相关性和其他相关特性。

# 介绍

在多标签学习中，每个实例都具有多个标签，并且多标签学习的任务就是为一个未知实例预测一组相关标签集。多标签学习被广泛的用于多种问题中，如文本分类、场景分类、基因组功能分类、视频分类、化学品分类等。多标签学习任务在现实问题中无处不在，引起了越来越多的研究关注。

一个最直接的方法就是把多标签学习问题转发为每个独立标签的二分类问题，并且这种方法已经在实践中被广泛的使用。这种方法的目的是能够充分使用现有的具有较高性能的单标签分类训练方法，但是当标签空间较大时，这种方法会带来较高的计算代价。此外，这种方法忽略了标签上的信息对于其他相关标签的学习具有一定帮助的事实，因此就限制了该方法的预测性能。发现标签之间的相关已经被证明是提高多标签学习性能的关键。因此，越来越多的多标签许欸小方法被提出来发现和探索标签之间的相关性。

不同于传统的多标签方法，深度神经网络模型通常会尝试学习一个新的特征空间，并在顶部使用一个多标签分类器。最早使用网络结构来解决多标签问题的是BP-MLL，该方法不仅把每个节点的输出作为一个二元分类任务，并且还利用了与网络自身结构相关的标签相关性。后来，又提出了一个基于BP-MLL的较为简单的神经网络方法，该方法使用熵损失替代了原先的排序损失，并且使用了深度神经网络技术，从而使得在大规模文本分类中取得了较好的效果。但是，深度神经网络通常需要大量的训练数据，因此就不适合小规模的数据集。

基于深度学习的逐层处理、模型特征变换和足够的模型复杂度的本质，提出了深度森林。深度森林是一个基于决策树的集成深度模型，但是在训练过程中不适用反向传播。具有级联结构的深度森林集成系统能够像深度神经网络模型一样进行表示学习。深度森林具有较少的超参，训练起来也更加容易。目前，它在大规模金融欺诈检测、图像、文本重建等一系列任务上都取得了优异的性能。虽然，深度森林已经被证明在传统分类任务中的有效性，但是在之前的工作中，深层森林应用于多标签学习的潜力并没有被注意到。

# 参考资料

[1] [周志华团队：深度森林挑战多标签学习，9大数据集超越传统方法](https://www.zhuanzhi.ai/document/430049ace146346a4859fa4c111b1a16)