---
title: AutoEncoder理解和推导
mathjax: true
date: 2020-07-01 20:24:37
updated: {{ date }}
tags: [机器学习]
categories: [机器学习]
---

自编码器是神经网络的一种，经过训练后能尝试将输入复制到输出。自编码器内部由一个隐藏层$h$，可以产生编码表示输入。该网络可以看作由两部分组成：一个由函数$h=f(x)$表示的编码器和一个生成重构的解码器$r=g(h)$。

# 欠完备自编吗器

从自编码器获得有用特征的一种方法是**限制$h$的维度比$x$小**，这种编码维度小于输入维度的自编码器称为欠完备自编码器。学习欠完备自编码器的表示将强制自编码器捕捉训练数据中最显著的特征。其最小化损失函数为

$$L(x,g(f(x)))$$

当解码器是线性的且$L$是均方误差，**欠完备的自编码器会学习出与PCA相同的生成子空间**，即训练数的主元子空间。不幸的是，**如果编码器和解码器被赋予过大的容量，自编码器会执行复制任务而捕捉不到任何有关数据分布的有用信息。**

# 正则自编码器

通过正则自编码器，即使模型容量大到足以学习一个无意义的恒等函数，非线性且过完备的正则自编码器仍然能够从数据中学到一些关于数据分布有用的信息。

## 稀疏自编码器

稀疏自编码器简单地在训练时结合编码层的稀疏惩罚项$\Omega (h)$和重构误差

$$L(x, g(f(x)))+\Omega (h)$$

其中$g(h)$是解码器的输出，通常$h$是编码器的输出，即$h=f(x)$。