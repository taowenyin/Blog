---
title: 【2018】Fast Multi-Instance Multi-Label Learning
mathjax: true
date: 2020-02-09 09:53:06
updated: {{ date }}
tags: [多标签学习, 深度学习]
categories: [论文]
---

# 摘要

在许多实际任务中，特别是那些涉及图像、文本等语义复杂的数据对象的任务中，一个对象可以用多个实例表示，同时与多个标签相关联。这些任务都可以表示为多实例多标签学习（MIML）问题，并且近几年得到了广泛的研究。现有的MIML方法已经在许多应用中得到证明是有用的；然而，这些方法中的大部分只能处理中等规模的数据。为了有效的处理大型数据集，本文作者提出了“MIML-Fast”方法，该方法首先构建了一个所有标签共享的低维子空间，然后通过随即梯度下降（SGD）来训练特定的标签线性模型来近似标签的排序损失。尽管MIML问题非常复杂，但是MIML-Fast能够利用共享空间中标签之间的关系发现复杂的标签子关系，从而获得优秀的性能。试验表明，MIML-Fast的性能与目前最先进的技术相当，但是却花费更少的时间。此外，MIML-Fast方法能够识别每个标签最具代表性的实例，从而提供了一个了解输入模式和输出标签语义之间关系的机会。

# 介绍

在传统的监督学习中，一个对象表示为一个实例，并且只与一个标签相关联。然而，在许多实际应用中，一个对象可以由多个实例来描述，并且关联多个标签分类。例如，在图像分类任务中，一个图像可以与多个语义标签相关联，并且可以分成多个段落，每个段落由一个实例来表示，如图1所示。在文本分类中，一篇文章可能属于多个分类，并且可以使用一个实例包来进行表示，每个段落代表一个实例；在基因功能预测人物中，一个基因通常与多个标签关联，因为这个基因与多个功能相关，并且可以通过一组不同视图的图像来表达。因此，MIML学习是近几年提出的面向复杂对象的学习框架。

{% asset_img miml-example.png MIML实例 %}

图1：MIML实例：图像由多个实例表示，并与多个标签关联

在过去几年，许多MIML算法被提出，并且其中的一些方法是把任务进行简化。例如，MIMLBoost把MIML任务简化为彝族多实例单标签的学习任务；MIMLSVM则通过把一个实例包转化为单实例来把任务简化为多标签学习任务。而DMIMLSVM方法则直接优化了MIML任务中的损失函数。还有其他相关的工作来试图使用现有的技术来解决MIML任务。

该方法获得了良好的性能，并且验证了MIML框架在各种应用中的优越性。然而，随着表达能力的增强，MIML的假设空间急剧膨胀，导致现有方法较高的复杂性和较低的效率。这些方法通常比较耗时，并且不能处理大规模数据，严重限制了应用MIML的学习。

为了克服这个问题，本文中，作者提出了一个全新的方法“MIML-Fast”来加速在MIML中数据的学习。尽管为提高效率采用了简单的线性模型，但MIML-Fast可以有效地近似原始的MIML问题。具体来说，为了有效利用多标签之间的关系，作者首先从所有标签的原始特征中得到一个共享空间，然后从共享空间中训练一个标签的线性模型。为了识别具有关键特征的标签实例包，作者训练了一个用于划分实例等级的分类模型，并且选择具有最大预测值的实例作为关键实例。为了使学习的高效性，作者使用了随机梯度下降（SGD）来优化排序损失。在SGD的每步中，MIML-Fast随即采样了一个元组，其中包含一个包，一个包相关的标签和一个不相关的标签，并且优化模型，使其排在不相关标签之前。与目前最先进的MIML方向相比，MIML-Fast具有很强的竞争性，并且在大数据集上的性能提高了100倍。

虽然大多数现有方法主要侧重于改进方法的泛化性，但MIML学习的另一个重要任务是理解输入模式和输出标签语义之间的相关性，即利用实例和标签之间的对应关系。作者的方法能够根据实例级别的预测来得到每个标签最典型的实例。

此外，我们的方法尝试利用标签的子关系来处理复杂的标签。通过对每个标签自适应多个模型，该方法可以区分复杂标签中嵌入的不同子概念。

# 相关工作

作者首先回顾了两个与MIML相关的学习框架，分别是多标签多系和多实例学习。

在多标签学习中，每个对象都可以表示为一个实例，并且这个实例有多个相关的标签。在过去许多年中多标签学习已经被很好的研究，并且提出了许多算法。目前的方法可以被分为两类，分别是问题转换法和算法适配法。在问题转换法中，最简单的方法就是把多标签任务分解为一串二分类问题，每一个问题对应一个标签，每个标签不具有相关性。而其他方法则试图把多标签任务转化为多分类问题，其中每个类都都可能是一个标签的子集。在算法适配法中尝试将流行的学习技术应用到多标签中。代表方法包括Boosting风格算法AdaBoost.MH，惰性学习算法ML-KNN，基于决策树的算法ML-DT，基于神经网络的算法。此外，弱监督的多标签学习已经在研究，无论是主动查询还是局部标注。近年来，如果利用标签之间的关系越来越引起研究者的兴趣。这方面的工作包括利用标签结构的先验知识和自动挖掘标签之间的相关性。

多实例学习最初是由Dietterich等人提出的，应用于药物活性预测。在该框架下，每个对象都可以用一组实例来进行描述，并与一个标签进行关联。学习任务在没有实例注释的情况下是弱监督的，因此具有相当大的挑战性。许多流程的机器学习方法已经用于多实例的表达。例如，决策树算法MITI，核方法Mi-Kernel和边缘化的Mi-Kernel，惰性学习算法Citation-knn和Bayesian-knn，以及集成方法HSMILE。

MIML学习是一个更为通用的框架。如文献中所述，多学习框架的存在是由于在表达现实世界的对象中存在歧义性。MIML同时考虑了输入和输出空间的歧义性，因此更自然和方便地处理涉及此类对象的任务。图2总结了四种学习框架之间的差异。

{% asset_img four-different-learning-frameworks.png 四种学习框架之间的差异 %}

图2：四种学习框架之间的差异

过去几年许多MIML方法被提出。例如，MIMLSVM会把MIML问题转化为单实例多标签任务来解决。MIMLBoost把MIML问题转化为多实例单标签任务来解决。一种MIML的生成模型被杨等人提出。文献中还提出了最近邻和神经网络方法。查等人提出了一种用于MIML图像标注的隐藏条件随机场模型。Briggs等人提出了在MIML标识时的优化排序损失。在文献中，作者试图通过为每个带聚类的标签构造一个原型来发现哪些模式触发了MIML学习中的哪些标签。最近，有一些研究试图将MIML框架扩展到新的环境中，包括类扩展、多视图学习和实例聚类。现有的MIML方法已经成功应用在许多场景中，由于计算量大，所以大多数应用于中等规模的数据。要处理大规模的数据，MIML就需要高效的方法。

在查阅前期的文章中，一些新的研究被提出。如文献31中提出了一种判别概率模型。该方法侧重于实例的标注，而不是在MIML环境下的包标注，并且提出了一种计算实例标签后验概率的动态规划方法。在文献12中，作者提出了一种深度MIML模型，该模型自动学习实例的描述，而不是手工设计实例的描述。在文献43中，另一个解决MIML学习的名叫MIML-FCN+的深度模型被提出。在文献1中，提出了一种具有多变量性能度量的可扩展优化方法。此外，激活标签查询和新类别发现也在MIML学习环境下被研究。

有一些研究试图通过排名来实现分类。在文献40中，一个类似的技术被用于优化图片标注中的WARP损失；然而，它处理的是单实例单标签问题，这与我们的MIML问题大不相同。在文献55中，提出了一种基于聚类的复杂概念中子概念发现的方法。然而，该方法关注的是但标签学习，也与我们的MIML任务不同。在MIML-Fast方法中利用标签信息，使用监督模型而不是启发式聚类来发现子概念。