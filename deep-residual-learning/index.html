<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/atom.xml" title="BearCoding" type="application/atom+xml"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><meta name="description" content="摘要深度神经网络越来越难训练。作者提出了一种残差学习框架，该框架能够简化那些非常深的网络训练。该框架使得网路层能够根据其输入来学习残差函数，而非原始函数。通过全面的试验表明，残差网络能够更加容易的优化，并且能够从较深的网络中获取更好的精度。在ImageNet数据集上，作者对152层的残差网络进行了评价，虽然该网络是VGG网络深度的8倍，但是仍然具有较低的复杂性。一个残差网络的组合模型在ImageN"><meta name="keywords" content="深度学习"><meta property="og:type" content="article"><meta property="og:title" content="【2016】Deep Residual Learning for Image Recognition"><meta property="og:url" content="bearcoding.cn&#x2F;deep-residual-learning&#x2F;index.html"><meta property="og:site_name" content="BearCoding"><meta property="og:description" content="摘要深度神经网络越来越难训练。作者提出了一种残差学习框架，该框架能够简化那些非常深的网络训练。该框架使得网路层能够根据其输入来学习残差函数，而非原始函数。通过全面的试验表明，残差网络能够更加容易的优化，并且能够从较深的网络中获取更好的精度。在ImageNet数据集上，作者对152层的残差网络进行了评价，虽然该网络是VGG网络深度的8倍，但是仍然具有较低的复杂性。一个残差网络的组合模型在ImageN"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="&#x2F;deep-residual-learning&#x2F;training-error.png"><meta property="og:image" content="&#x2F;deep-residual-learning&#x2F;building-block.png"><meta property="og:updated_time" content="2020-05-20T13:52:11.792Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="&#x2F;deep-residual-learning&#x2F;training-error.png"><link rel="canonical" href="bearcoding.cn/deep-residual-learning/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>【2016】Deep Residual Learning for Image Recognition | BearCoding</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">BearCoding</span><span class="logo-line-after"><i></i></span></a></div></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li class="menu-item menu-item-publication"><a href="/categories/%E5%8F%91%E8%A1%A8" rel="section"><i class="fa fa-fw fa-leanpub"></i> 发表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><div class="reading-progress-bar"></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="bearcoding.cn/deep-residual-learning/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="陶文寅"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="BearCoding"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> 【2016】Deep Residual Learning for Image Recognition</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-05-19 09:28:20" itemprop="dateCreated datePublished" datetime="2020-05-19T09:28:20+08:00">2020-05-19</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2020-05-20 21:52:11" itemprop="dateModified" datetime="2020-05-20T21:52:11+08:00">2020-05-20</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E8%AE%BA%E6%96%87/" itemprop="url" rel="index"><span itemprop="name">论文</span></a></span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="摘要">摘要</h1><p>深度神经网络越来越难训练。作者提出了一种残差学习框架，该框架能够简化那些非常深的网络训练。该框架使得网路层能够根据其输入来学习残差函数，而非原始函数。通过全面的试验表明，残差网络能够更加容易的优化，并且能够从较深的网络中获取更好的精度。在ImageNet数据集上，作者对152层的残差网络进行了评价，虽然该网络是VGG网络深度的8倍，但是仍然具有较低的复杂性。一个残差网络的组合模型在ImageNet的测试集上达到了3.57%的错误率。这个结果在ILSVRC2015的分类分类任务中取得了第一名。同时，我们也分析了在CIFAR-10数据集上100层和1000层的残差网络。</p><a id="more"></a><p>表达的深度在很多视觉识别任务中是至关重要的。仅仅只是采用了较深的表达，便在COCO目标检测数据集上获得28%的性能提升。深度残差网络是作者参加ILSVRC和COCO2015竞赛上所使用的模型基础，且作者在ImageNet检测、ImageNet定位、COCO检测以及COCO分割上均获得了第一名的成绩。</p><h1 id="介绍">介绍</h1><p>深度卷积神经网络在图像分类上取得了一系列的突破。深度网络以端到端的多层方式很好的集成了低、中、高层的的特征和分类器，特征的层次可以通过多层的堆叠来丰富。最近的研究表明，网络的深度是至关重要的，在具有挑战性的ImageNet数据集上，最好的结果都采用了16-30层深度的网络模型。此外，许多有难度的视觉识别任务也能够从非常深的模型上获得较好的结果。</p><p><strong>在网络深度的驱使下，一个新的问题产生了：训练一个更好的网络是不是就像堆叠更多的网络层一样容易？</strong> 回答这个问题的障碍就是困扰人们很久的梯度消失/梯度爆炸问题，这个问题从一开始就阻止了模型的收敛。然而，这个问题已经在很大程度上通过归一化和中间归一化层得到了解决，使得数十层的网络能够通过反向传播的随即梯度下降能够是进行收敛。</p><p>当深度网络开始收敛时，退化问题又暴露了出来：随着网络深度的增加，模型的精度会饱和（这并不奇怪），然后迅速的退化。出乎意料的是，这种退化并不是过拟合造成的，并且当向模型增加更多层时会造成更高的错误率。作者的实验也证明了这一点，图1是一个典型的例子。</p> <img src="/deep-residual-learning/training-error.png" class title="训练与测试误差"><p>图1：在CIFAR-10数据集上20层和56层平原网络的训练误差（左）和测试误差（右）。更深的网络有更高的训练误差和测试误差。在ImageNet数据集上有类似现象，如图4所示。</p><p>退化的出现表示并非所有的系统都容易被优化。作者比较了一个网络的浅层结构和对应的深层结构。有一个解决方案可以构建更深的模型：添加一个<strong>恒等映射层</strong>，而其他层则直接从浅层模型映射过来。这个结构的深度模型表示一个深度模型不应该有比浅层网络更高的错误率。但是实现表明，作者目前无法找到一个与这种构建的解决方案相当或者更好的方案（或者说无法在可行的时间内实现）。</p><p>在本论文中，作者通过引入了<strong>深度残差网络框架</strong> 解决了退化问题。我们明确的让这些层来拟合残差映射，而不是让每一个堆叠的层直接来拟合所需的底层映射。形式上，假设所需的底层映射为<span class="math inline">\(\mathcal{H}(\mathbf{x})\)</span>，作者让叠加的非线性层拟合另一个映射<span class="math inline">\(\mathcal{F}(\mathbf{x}):=\mathcal{H}(\mathbf{x})-\mathbf{x}\)</span>。那么原始映射就被重新转化为<span class="math inline">\(\mathcal{F}(\mathbf{x})+\mathbf{x}\)</span>。作者推断残差映射比原始未参考的印社更容易优化。在极端情况下，如果一个恒等映射是最优的，那么把残差优化为0比通过堆叠线性层来拟合恒等要更加容易。</p><p>式子中的<span class="math inline">\(\mathcal{F}(\mathbf{x})+\mathbf{x}\)</span>能够通过有“快捷连接”的前向神经网络来实现（如图2所是）。“快捷连接”能够跳过一个或多个网路层。在作者的例子中。“快捷连接”的作用只是简单的执行恒等映射，并“快捷连接”的输出被添加到堆叠的网络层的输出上。恒等映射的“快捷连接”并没有增加额外的参数和计算复杂度。整个网络依然可以通过反向传播SGD实现端到端的训练，并且可以在不修改求解器的情况下使用公共库来轻松实现。</p> <img src="/deep-residual-learning/building-block.png" class title="残差学习"><p>图2：残差学习：一个基本结构</p><p>作者在ImageNet上进行了全面的实验，以显示退化问题，并评估作者的方法。通过实验表明：1）作者的深度残差网络可以很容易的优化，而相应“平原”网络（通过简单的堆叠层）在深度增加时表现出更高的训练误差。2）作者的深度残差网络能够很容易的从网络深度大幅增加中获得精度增益，而产生的结果比以前的网络要好得多。</p><p>CIFAR-10数据集中也有类似的现象，这表明了作者提出的方法的优化难度和效果并不仅仅是对于一个特定数据集。</p><h1 id="相关工作">相关工作</h1><h1 id="深度残差学习">深度残差学习</h1><h2 id="残差学习">残差学习</h2><h2 id="通过快捷方式实现恒等映射">通过快捷方式实现恒等映射</h2><h2 id="网络结构">网络结构</h2><h2 id="实现">实现</h2><h1 id="实验">实验</h1><h2 id="imagenet分类">ImageNet分类</h2><h2 id="cifa-10以及分析">CIFA-10以及分析</h2><h2 id="pascal和ms-coco的目标检测">PASCAL和MS COCO的目标检测</h2></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> 陶文寅</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="/bearcoding.cn/deep-residual-learning/" title="【2016】Deep Residual Learning for Image Recognition">bearcoding.cn/deep-residual-learning/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/pc-homework/" rel="next" title="模式识别原理作业"><i class="fa fa-chevron-left"></i> 模式识别原理作业</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></article></div></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#摘要"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#介绍"><span class="nav-number">2.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#相关工作"><span class="nav-number">3.</span> <span class="nav-text">相关工作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度残差学习"><span class="nav-number">4.</span> <span class="nav-text">深度残差学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#残差学习"><span class="nav-number">4.1.</span> <span class="nav-text">残差学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过快捷方式实现恒等映射"><span class="nav-number">4.2.</span> <span class="nav-text">通过快捷方式实现恒等映射</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络结构"><span class="nav-number">4.3.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实现"><span class="nav-number">4.4.</span> <span class="nav-text">实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#实验"><span class="nav-number">5.</span> <span class="nav-text">实验</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#imagenet分类"><span class="nav-number">5.1.</span> <span class="nav-text">ImageNet分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cifa-10以及分析"><span class="nav-number">5.2.</span> <span class="nav-text">CIFA-10以及分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pascal和ms-coco的目标检测"><span class="nav-number">5.3.</span> <span class="nav-text">PASCAL和MS COCO的目标检测</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">陶文寅</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">37</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">14</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="/mailto:wenyin.tao@163.com" title="E-Mail &amp;rarr; mailto:wenyin.tao@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> E-Mail</a></span></div><div class="cc-license motion-element" itemprop="license"> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2020</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">陶文寅</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0</div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script><script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script></body></html>